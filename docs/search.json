[
  {
    "objectID": "cv/index.html",
    "href": "cv/index.html",
    "title": "Curriculum vitae",
    "section": "",
    "text": "Download current CV\n  \n\n\n  \n\n\nView the tutorial for this template (+ download link)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to my website!",
    "section": "",
    "text": "Github\n  \n  \n    \n     LinkedIn\n  \n  \n    \n     Email\n  \n\n\n\n\nWelcome to my website!\nI am Amr Salem, a dedicated master’s student in applied mathematics and biostatistics at Case Western Reserve University, with a passion for exploring the potential of data science and statistical modeling in advancing healthcare. Currently, I work at the UroGenetics Lab under the guidance of Dr. Chen-Han Wilfred Wu, where I am involved in cutting-edge research at the intersection of genomics and machine learning.\nMy research focuses on statistical genomics, with an emphasis on leveraging computational tools to address complex biological challenges. Projects such as predicting kidney stone risk using convolutional neural networks and developing polygenic risk scores have allowed me to combine my academic training with innovative methodologies to generate impactful insights.\nAs a researcher and student, I am passionate about learning, discovery, and collaboration. My experience spans diverse projects, from abstract presentations to hands-on analysis, and I thrive in environments where interdisciplinary approaches and creative problem-solving are valued.\nOn this page, you will find updates on my research projects, academic pursuits, and insights into the ever-evolving fields of genomics and biostatistics.\nPlease feel free to contact me if you have any questions or would like to discuss potential projects.\n\nView the tutorial for this template (+ download link)"
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "Journey",
    "section": "",
    "text": "I am currently pursuing Integrated Graduate Studies (BS/MS) at Case Western Reserve University, majoring in Applied Mathematics and Biostatistics. This unique program allows me to blend advanced mathematical techniques with biostatistical methods, focusing on applying data science to real-world healthcare challenges. My undergraduate and graduate coursework has provided me with a solid foundation in mathematical modeling, computational analysis, and predictive analytics."
  },
  {
    "objectID": "projects/index.html#education",
    "href": "projects/index.html#education",
    "title": "Journey",
    "section": "",
    "text": "I am currently pursuing Integrated Graduate Studies (BS/MS) at Case Western Reserve University, majoring in Applied Mathematics and Biostatistics. This unique program allows me to blend advanced mathematical techniques with biostatistical methods, focusing on applying data science to real-world healthcare challenges. My undergraduate and graduate coursework has provided me with a solid foundation in mathematical modeling, computational analysis, and predictive analytics."
  },
  {
    "objectID": "projects/index.html#experience",
    "href": "projects/index.html#experience",
    "title": "Journey",
    "section": "Experience",
    "text": "Experience\n\nWu Lab at Case Western Reserve University (2022–Present)\nAt the Wu Lab, I have been working on applying data science to better understand and improve the management of kidney stone disease. My projects involve integrating computational and statistical methods to analyze large-scale genomic datasets, with the goal of identifying patterns and predictors in the disease’s progression and recurrence. This work has deepened my understanding of precision medicine and the application of biostatistics in translational research.\n\n\nGillani Lab at Dana-Farber Cancer Institute (Starting Summer 2025)\nThe Gillani Lab is dedicated to advancing pediatric, adolescent, and young adult cancer care through innovative computational biology approaches. Their mission is to contribute to a comprehensive understanding of germline genetics and tumor genomics in pediatric cancer, with the goal of informing novel management strategies.\nI am excited to join this dynamic team and contribute to their vision of improving pediatric cancer care using cutting-edge computational biology."
  },
  {
    "objectID": "projects/index.html#research-projects",
    "href": "projects/index.html#research-projects",
    "title": "Journey",
    "section": "Research Projects",
    "text": "Research Projects\n\nPredicting Kidney Stone Risk Using Genomic Data\nThis project aimed to predict kidney stone susceptibility using genomic data. Under the guidance of Dr. Anirban Mondal, I developed a Convolutional Neural Network (CNN) model to analyze genotypic data from 60 individuals, encompassing over 400 SNPs identified from genome-wide association studies (GWAS). The model achieved an accuracy of 75% and an ROC-AUC of 0.8125, providing promising insights into genetic predispositions to kidney stones.\nA major challenge was working with a relatively small dataset, which required careful optimization of model parameters and validation techniques to ensure robust predictions. This experience honed my ability to combine biological context with computational tools, paving the way for future research involving larger datasets and integration of clinical features.\n\n\nDisease Course of Kidney Stones\nThis project investigates the disease course of kidney stones, focusing on the factors influencing their progression and recurrence. By leveraging clinical and genomic data, we aim to develop predictive models that can assist in tailoring treatment strategies for patients. My contributions include data preprocessing, feature selection, and implementing machine learning pipelines to identify key predictors. This research has the potential to inform more personalized approaches to managing kidney stone disease.\n\n\nView the tutorial for this template (+ download link)"
  },
  {
    "objectID": "photography/index.html",
    "href": "photography/index.html",
    "title": "Photography",
    "section": "",
    "text": "As a wizard and scholar of Middle-earth, I have been studying the magic of the natural world for centuries. Through my self-portraits, I aim to capture the essence of my own being and reflect on my own journey through time. Each photograph is a reflection of my own experiences and emotions. Through my photography, I hope to offer a glimpse into my life as a scholar and adventurer, and inspire others to reflect on their own journeys through the world.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nView the tutorial for this template (+ download link)"
  },
  {
    "objectID": "dashboard/Blog.html",
    "href": "dashboard/Blog.html",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "",
    "text": "Cardiovascular disease (CVD) remains one of the leading causes of death globally, with cholesterol levels playing a critical role in assessing an individual’s risk. Cholesterol, particularly low-density lipoprotein (LDL) and high-density lipoprotein (HDL), is closely associated with the development of cardiovascular diseases. Understanding the relationship between various factors such as body mass index (BMI), smoking habits, hypertension, and age can provide valuable insights into how these risk factors contribute to elevated cholesterol levels and overall cardiovascular health.\nThe National Health and Nutrition Examination Survey (NHANES) provides an extensive dataset that can be used to explore the correlation between lifestyle factors, health indicators, and cholesterol levels. In this study, we examine NHANES pre-pandemic data, focusing on various health factors, including BMI, smoking, age, hypertension, and cholesterol levels. Our goal is to explore how these factors can be utilized to predict cholesterol risk, ultimately informing public health strategies and interventions.\nBy analyzing these relationships, we aim to better understand how different variables impact cholesterol levels and to identify the most significant predictors of cardiovascular risk. The results from this study can help in the development of targeted interventions and health guidelines for individuals at risk of developing heart disease.\nThis report reflects the analysis behind the dashboard, which presents the findings and insights from this study. Throughout the report, each analysis is accompanied by a subsection that discusses the choices made during the analysis process, including variable selection, modeling decisions, and the rationale behind visualizations displayed on the dashboard. These discussions aim to provide transparency into the methodology and ensure that the interpretation of the results is grounded in the data and analytical approach."
  },
  {
    "objectID": "dashboard/Blog.html#codebook",
    "href": "dashboard/Blog.html#codebook",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "3.1 Codebook",
    "text": "3.1 Codebook\n\n# Load required library\n\n# Create the codebook\ncodebook &lt;- tibble::tibble(\n  Variable_Name = c(\n    \"SEQN\", \n    \"LDL\", \"HDL\", \n    \"BMI\", \"Gender\", \n    \"Total_Cholesterol\", \"Age_Group\", \n    \"Smoking_Status\", \"Hypertension_Status\",\"vigorous_activity_days\"\n  ),\n  Variable_Type = c(\n    \"Identifier\", \n    \"Quant\", \"Quant\", \n    \"Quant\", \"Binary\", \n    \"Quant\", \"8-cat\", \n    \"Binary\", \"Binary\", \"Quant\"\n  ),\n  Original_Name = c(\n    \"SEQN\", \n    \"LBXTR\", \"LBDHDD\", \n    \"BMXBMI\", \"RIAGENDR\", \n    \"LBXTC\", \"RIDAGEYR\", \n    \"SMQ020\", \"BPQ020\",\"PAQ655\"\n  )\n)\n\n# Print the codebook\nsuppressWarnings({\n  knitr::kable(\n    codebook,\n    col.names = c(\"Variable Name\", \"Variable Type\", \"Original Name\"),\n    caption = \"Codebook for Variables Used in Analyses\"\n  )\n})\n\n\nCodebook for Variables Used in Analyses\n\n\nVariable Name\nVariable Type\nOriginal Name\n\n\n\n\nSEQN\nIdentifier\nSEQN\n\n\nLDL\nQuant\nLBXTR\n\n\nHDL\nQuant\nLBDHDD\n\n\nBMI\nQuant\nBMXBMI\n\n\nGender\nBinary\nRIAGENDR\n\n\nTotal_Cholesterol\nQuant\nLBXTC\n\n\nAge_Group\n8-cat\nRIDAGEYR\n\n\nSmoking_Status\nBinary\nSMQ020\n\n\nHypertension_Status\nBinary\nBPQ020\n\n\nvigorous_activity_days\nQuant\nPAQ655"
  },
  {
    "objectID": "dashboard/Blog.html#the-question",
    "href": "dashboard/Blog.html#the-question",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "4.1 The Question",
    "text": "4.1 The Question\nThe relationship between HDL (high-density lipoprotein) and LDL (low-density lipoprotein) cholesterol levels is of particular interest in understanding cardiovascular health. HDL is often referred to as “good cholesterol” due to its role in transporting cholesterol away from the arteries, while LDL is called “bad cholesterol” because high levels can lead to plaque buildup in arteries.\nPre-existing Belief: Before analyzing the data, it is expected that there is an inverse relationship between HDL and LDL levels. That is, individuals with higher HDL levels tend to have lower LDL levels, as HDL is thought to counteract the effects of LDL.\nResearch Question: Is there a significant difference between high-density lipoprotein (HDL) cholesterol and low-density lipoprotein (LDL) cholesterol levels?"
  },
  {
    "objectID": "dashboard/Blog.html#data-description",
    "href": "dashboard/Blog.html#data-description",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "4.2 Data Description",
    "text": "4.2 Data Description\n\n# Create the codebook table\ndata_description &lt;- data.frame(\n  Variable_Name = c(\"HDL_Level\", \"LDL_Level\", \"Age_Group\", \"Gender\"),\n  Description = c(\"High-density lipoprotein cholesterol (mg/dL)\",\n                  \"Low-density lipoprotein cholesterol (mg/dL)\",\n                  \"Age categorized into groups\",\n                  \"Gender of the participant\"),\n  Type = c(\"Quantitative\", \"Quantitative\", \"8-Cat\", \"Binary\"),\n  Original_Variable_Name = c(\"LBDHDD\", \"LBXLDL\", \"RIDAGEYR\", \"RIAGENDR\")\n)\n\n# View the data description table\ndata_description\n\n  Variable_Name                                  Description         Type\n1     HDL_Level High-density lipoprotein cholesterol (mg/dL) Quantitative\n2     LDL_Level  Low-density lipoprotein cholesterol (mg/dL) Quantitative\n3     Age_Group                  Age categorized into groups        8-Cat\n4        Gender                    Gender of the participant       Binary\n  Original_Variable_Name\n1                 LBDHDD\n2                 LBXLDL\n3               RIDAGEYR\n4               RIAGENDR\n\n\nThe following is a summary of the data:\n\n# Numeric summaries for HDL and LDL\nsummary_stats &lt;- HDL_vs_LDL %&gt;%\n  summarise(\n    HDL_Min = min(HDL, na.rm = TRUE),\n    HDL_Max = max(HDL, na.rm = TRUE),\n    HDL_Mean = mean(HDL, na.rm = TRUE),\n    HDL_Median = median(HDL, na.rm = TRUE),\n    HDL_SD = sd(HDL, na.rm = TRUE),\n    LDL_Min = min(LDL, na.rm = TRUE),\n    LDL_Max = max(LDL, na.rm = TRUE),\n    LDL_Mean = mean(LDL, na.rm = TRUE),\n    LDL_Median = median(LDL, na.rm = TRUE),\n    LDL_SD = sd(LDL, na.rm = TRUE)\n  )\n\n# View the summary statistics\npivoted_stats &lt;- summary_stats %&gt;%\n  pivot_longer(cols = everything(), \n               names_to = c(\"Type\", \"Statistic\"), \n               names_sep = \"_\") %&gt;%\n  pivot_wider(names_from = \"Type\", values_from = \"value\")\n\n# View the pivoted statistics\npivoted_stats# View the summary statistics\n\n# A tibble: 5 × 3\n  Statistic   HDL    LDL\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n1 Min        11     10  \n2 Max       187   2684  \n3 Mean       53.6  104. \n4 Median     51     84  \n5 SD         15.5   89.8\n\n\nThe following is the density plot of HDL vs LDL to examine the data.\n\n# Step 10: Density plot with log transformation and legend\nggplot(HDL_vs_LDL) +\n  # Density plot for log-transformed Triglycerides (LBXTR)\n  geom_density(aes(x = (LDL), fill = \"Triglycerides\"), color = \"black\", alpha = 0.6) +\n  # Density plot for log-transformed HDL Cholesterol (LBDHDD)\n  geom_density(aes(x = (HDL), fill = \"HDL Cholesterol\"), color = \"black\", alpha = 0.6) +\n  labs(\n    title = \"Density Plot of Log-Transformed Triglycerides and HDL Cholesterol\",\n    x = \"Log(Concentration)\",\n    y = \"Density\"\n  ) +\n  scale_fill_manual(name = \"Variable\", values = c(\"Triglycerides\" = \"skyblue\", \"HDL Cholesterol\" = \"lightgreen\")) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    axis.title = element_text(size = 10),\n    axis.text = element_text(size = 8),\n    legend.title = element_text(size = 7),\n    legend.text = element_text(size = 7)\n  )\n\n\n\n\n\n\n\n\nI decided to apply a log transformation to both HDL and LDL cholesterol levels was primarily driven by the observed skewness in the original data distributions. Cholesterol levels, particularly in population studies, often follow a right-skewed distribution, meaning that a majority of the values are clustered at lower levels, with a long tail extending towards higher values.\nThe following is the density plot after transformation:\n\n# Step 10: Density plot with log transformation and legend\nggplot(HDL_vs_LDL) +\n  # Density plot for log-transformed Triglycerides (LBXTR)\n  geom_density(aes(x = log(LDL), fill = \"Triglycerides\"), color = \"black\", alpha = 0.6) +\n  # Density plot for log-transformed HDL Cholesterol (LBDHDD)\n  geom_density(aes(x = log(HDL), fill = \"HDL Cholesterol\"), color = \"black\", alpha = 0.6) +\n  labs(\n    title = \"Density Plot of Log-Transformed Triglycerides and HDL Cholesterol\",\n    x = \"Log(Concentration)\",\n    y = \"Density\"\n  ) +\n  scale_fill_manual(name = \"Variable\", values = c(\"Triglycerides\" = \"skyblue\", \"HDL Cholesterol\" = \"lightgreen\")) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5),\n    axis.title = element_text(size = 10),\n    axis.text = element_text(size = 8),\n    legend.title = element_text(size = 7),\n    legend.text = element_text(size = 7)\n  )\n\n\n\n\n\n\n\nwrite.csv(HDL_vs_LDL,\"hdlvsldl.csv\", row.names = FALSE)"
  },
  {
    "objectID": "dashboard/Blog.html#main-analysis",
    "href": "dashboard/Blog.html#main-analysis",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "4.3 Main Analysis",
    "text": "4.3 Main Analysis\nHypotheses: Null Hypothesis (H₀): There is no significant difference between HDL and LDL cholesterol levels (i.e., the mean difference between HDL and LDL levels is zero). Alternative Hypothesis (H₁): There is a significant difference between HDL and LDL cholesterol levels (i.e., the mean difference between HDL and LDL levels is not zero).\nBefore conducting this analysis, I have a pre-existing belief based on general medical knowledge that HDL and LDL levels are likely to be different in most populations due to their differing roles in cardiovascular health—HDL is often referred to as “good” cholesterol, while LDL is termed “bad” cholesterol.\nChoice of Statistical Test:\nFor this analysis, I chose to perform a paired t-test, which is appropriate when comparing the means of two related groups (in this case, HDL and LDL cholesterol levels for the same subjects). The paired t-test is used to assess whether the difference in cholesterol levels between the two measures is statistically significant.\nThe decision to use a paired t-test was made because:\nPaired Data: The same individuals provide measurements for both HDL and LDL cholesterol, making the data “paired.” This allows us to examine whether there is a difference in cholesterol levels between the two types within the same subjects.\nAssumptions for the Paired t-Test: Paired Data: The data consists of paired observations, where each participant’s HDL and LDL levels are measured.\nScale of Measurement: Both HDL and LDL cholesterol levels are measured on an interval scale (mg/dL), making the use of a t-test appropriate.\n\n# Perform paired t-test\nttest_result &lt;- t.test(HDL_vs_LDL$LDL, HDL_vs_LDL$HDL, paired = TRUE)\n\n# Print the result of the t-test\nttest_result\n\n\n    Paired t-test\n\ndata:  HDL_vs_LDL$LDL and HDL_vs_LDL$HDL\nt = 35.582, df = 4649, p-value &lt; 2.2e-16\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 47.36787 52.89192\nsample estimates:\nmean difference \n       50.12989"
  },
  {
    "objectID": "dashboard/Blog.html#conclusion",
    "href": "dashboard/Blog.html#conclusion",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "4.4 Conclusion",
    "text": "4.4 Conclusion\nAnswer to the Research Question: The research question was: “Is there a significant difference between Triglyceride (LBXTR) and HDL Cholesterol (LBDHDD) levels in the study population?”\nBased on the results of the paired t-test, we can conclude that there is a statistically significant difference between the triglyceride and HDL cholesterol levels. The test statistic of 35.582 and the p-value is well below the significance threshold of 0.05. This means that we reject the null hypothesis that there is no difference between triglyceride and HDL cholesterol levels.\n95% Confidence Interval:\nThe 95% confidence interval for the mean difference in levels between triglyceride and HDL cholesterol is between 47.37 and 52.89. This suggests that, on average, triglyceride levels are significantly higher than HDL cholesterol levels in the study population.\nPre-existing Belief Reflection:\nMy belief that triglyc eride levels would be higher than HDL cholesterol levels based on prior knowledge of lipid profiles, the data supports this hypothesis. The mean difference between triglyceride and HDL cholesterol levels is 50.13. This aligns with the belief that triglycerides are generally higher than HDL in the studied population.\nLogical Next Steps: The next step could involve exploring the causal relationship between triglycerides and HDL cholesterol. For example, a regression model could be used to examine how various predictors, such as age, gender, smoking status, and BMI, influence the relationship between triglyceride and HDL cholesterol levels. Additionally, this analysis could be extended to investigate whether individuals with higher triglyceride levels also show an increased risk for cardiovascular diseases.\nLastly, future studies might want to explore other potential interactions between lipid profiles and other biomarkers, such as blood pressure or inflammatory markers, to provide a more comprehensive understanding of the cardiovascular health risks in the population."
  },
  {
    "objectID": "dashboard/Blog.html#reasoning-for-dashboard",
    "href": "dashboard/Blog.html#reasoning-for-dashboard",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "4.5 Reasoning for Dashboard",
    "text": "4.5 Reasoning for Dashboard\nThe goal of the dashboard is to provide clear and easily interpretable visualizations and key performance indicators (KPIs) that can help users quickly understand the relationship between triglyceride and HDL cholesterol levels, as well as assess the quality of lipid profiles in the study population.\nChosen Visualizations and KPIs Mean LDL-to-HDL Ratio:\nWhy Chosen: The LDL-to-HDL ratio is a commonly used metric to assess lipid balance, which plays a crucial role in cardiovascular health. A higher ratio suggests a higher risk of heart disease, making it a valuable indicator for monitoring lipid profiles in the population. Rationale for KPI: The mean ratio provides a quick, overall assessment of the population’s lipid balance. By comparing this value across different subgroups or over time, we can track trends and identify potential areas of concern.\nImplementation:\n\nlist(\n  icon = \"arrow-down-up\",\n  color = \"#ffe4b2\",\n  value = round(mean(HDL_vs_LDL$LDL / HDL_vs_LDL$HDL, na.rm = TRUE), 2)\n)\n\n$icon\n[1] \"arrow-down-up\"\n\n$color\n[1] \"#ffe4b2\"\n\n$value\n[1] 2.29\n\n\nHealthy Lipid Profiles (%):\nWhy Chosen: Healthy lipid profiles are typically defined by triglyceride levels under 100 mg/dL and HDL cholesterol levels above 60 mg/dL. This KPI reflects the proportion of individuals in the dataset who meet these criteria, providing insight into the overall cardiovascular health of the population. Rationale for KPI: Understanding the percentage of individuals with a healthy lipid profile allows stakeholders to evaluate the general health of the group, identify trends, and determine the need for public health interventions.\nImplementation:\n\nlist(\n  icon = \"heart\",\n  color = \"green\",\n  value = round(\n    mean(\n      HDL_vs_LDL$LDL &lt; 100 & HDL_vs_LDL$HDL &gt;= 60, na.rm = TRUE\n    ) * 100, \n    1\n  )\n)\n\n$icon\n[1] \"heart\"\n\n$color\n[1] \"green\"\n\n$value\n[1] 23.9\n\n\nHistograms of Triglycerides (LBXTR) and HDL Cholesterol (LBDHDD):\nWhy Chosen: Histograms provide an overview of the distribution of triglyceride and HDL cholesterol values in the population. These visualizations help identify patterns such as skewness, potential outliers, and the overall spread of the data. Rationale for Visualization: By examining the distribution of these lipid measures, we can better understand the population’s lipid profiles and identify areas where the data might need cleaning or further investigation (e.g., removing outliers).\nDensity Plot Comparison of Triglycerides and HDL Cholesterol:\nWhy Chosen: A density plot allows for a smooth estimation of the distribution of triglyceride and HDL cholesterol levels, making it easier to compare their shapes and spread. The log transformation is applied to both variables to reduce skewness and facilitate a more accurate comparison. Rationale for Visualization: This plot helps visualize the overlap (or lack thereof) between the two distributions, providing a deeper understanding of how triglycerides and HDL cholesterol differ in terms of their concentration distributions across the population."
  },
  {
    "objectID": "dashboard/Blog.html#the-question-1",
    "href": "dashboard/Blog.html#the-question-1",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "5.1 The Question",
    "text": "5.1 The Question\nResearch Question\nIs there a difference in BMI distribution between males and females?\nDescription of Study:\nIn this analysis, I want to explore the relationship between Body Mass Index (BMI) and gender. BMI is a key measure commonly used to assess whether individuals are underweight, normal weight, overweight, or obese, based on their height and weight. Given that BMI can influence health outcomes like cardiovascular risk, diabetes, and overall morbidity, understanding any potential gender differences in BMI distributions is important for targeted health interventions.\nPre-existing Belief:\nBefore examining the data, I believe that there will be a noticeable difference in BMI between genders, with women generally having higher average BMI values than men. This belief is based on well-established biological differences in body composition between the sexes. Specifically, women tend to have a higher percentage of body fat compared to men, who often have more muscle mass. As BMI is a function of both weight and height, and since muscle mass weighs more than fat, this could explain why women might have higher BMI values on average, even if they are at similar or slightly lower body weights compared to men. I expect this difference to be statistically significant based on prior research, though the magnitude of the difference will need to be confirmed through the data analysis."
  },
  {
    "objectID": "dashboard/Blog.html#data-descrption",
    "href": "dashboard/Blog.html#data-descrption",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "5.2 Data Descrption",
    "text": "5.2 Data Descrption\n\n# Create the codebook table\ndata_description_bmi_gender &lt;- data.frame(\n  Variable_Name = c(\"BMI\", \"Gender\"),\n  Description = c(\"Body Mass Index, calculated as weight (kg) / height (m)^2\",\n                  \"Gender of the participant (Male/Female)\"),\n  Type = c(\"Quantitative\", \"Binary\"),\n  Original_Variable_Name = c(\"BMXBMI\", \"RIAGENDR\")\n)\n\n# View the data description table\ndata_description_bmi_gender\n\n  Variable_Name                                               Description\n1           BMI Body Mass Index, calculated as weight (kg) / height (m)^2\n2        Gender                   Gender of the participant (Male/Female)\n          Type Original_Variable_Name\n1 Quantitative                 BMXBMI\n2       Binary               RIAGENDR\n\n\nThe data summaries:\n\n# Numeric summaries for BMI and Gender\nsummary_stats_bmi_gender &lt;- BMI_and_Gender %&gt;%\n  summarise(\n    BMI_Min = min(BMI, na.rm = TRUE),\n    BMI_Max = max(BMI, na.rm = TRUE),\n    BMI_Mean = mean(BMI, na.rm = TRUE),\n    BMI_Median = median(BMI, na.rm = TRUE),\n    BMI_SD = sd(BMI, na.rm = TRUE),\n    Gender_Male_Percentage = mean(Gender == \"Male\", na.rm = TRUE) * 100,  # assuming 1 is Male\n    Gender_Female_Percentage = mean(Gender == \"Female\", na.rm = TRUE) * 100   # assuming 2 is Female\n  )\n\nwrite.csv(BMI_and_Gender,\"BMI_data.csv\", row.names = FALSE)\n# View the pivoted statistics\nsummary_stats_bmi_gender\n\n# A tibble: 1 × 7\n  BMI_Min BMI_Max BMI_Mean BMI_Median BMI_SD Gender_Male_Percentage\n    &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt;  &lt;dbl&gt;                  &lt;dbl&gt;\n1    11.9    92.3     26.7       25.8   8.42                   49.2\n# ℹ 1 more variable: Gender_Female_Percentage &lt;dbl&gt;\n\n\nI used a violin plot and examine the data:\n\n# Boxplot to compare BMI between genders\nboxplot_bmi &lt;- ggplot(BMI_and_Gender, aes(x = Gender, y = BMI, fill = Gender)) +\n  geom_boxplot() +\n  labs(title = \"BMI Distribution by Gender\", x = \"Gender\", y = \"BMI\") +\n  theme_minimal()\nboxplot_bmi\n\n\n\n\n\n\n\n\nThere appear to be a lot of outliers in the violin plot, so I have removed them to get a clearer view of the data.\n\n# Remove outliers based on the IQR (Interquartile Range) method\nQ1 &lt;- quantile(BMI_and_Gender$BMI, 0.25, na.rm = TRUE)\nQ3 &lt;- quantile(BMI_and_Gender$BMI, 0.75, na.rm = TRUE)\nIQR_value &lt;- Q3 - Q1\nlower_limit &lt;- Q1 - 1.5 * IQR_value\nupper_limit &lt;- Q3 + 1.5 * IQR_value\n\n# Filter out the outliers\nBMI_and_Gender_no_outliers &lt;- BMI_and_Gender %&gt;%\n  filter(BMI &gt;= lower_limit & BMI &lt;= upper_limit)\n\n# Boxplot without outliers\nboxplot_bmi_no_outliers &lt;- ggplot(BMI_and_Gender_no_outliers, aes(x = Gender, y = BMI, fill = Gender)) +\n  geom_boxplot() +\n  labs(title = \"BMI Distribution by Gender (Without Outliers)\", x = \"Gender\", y = \"BMI\") +\n  theme_minimal()\n\n# Show the plot\nboxplot_bmi_no_outliers\n\n\n\n\n\n\n\n\nFemales seem to have a higher BMI than males. I will processed with the analysis to examine this relationship closer.\nThe following code plots histograms so I can examine the data on the gender-level.\n\nhistogram_bmi &lt;- ggplot(BMI_and_Gender, aes(x = BMI, fill = Gender)) +\n  geom_histogram(binwidth = 1, alpha = 0.6, position = \"identity\") +  # Adjust binwidth as needed\n  facet_wrap(~ Gender, scales = \"free_y\") +  # Facet by Gender\n  labs(title = \"BMI Distribution by Gender\", x = \"BMI\", y = \"Frequency\") +\n  theme_minimal()\n\nhistogram_bmi\n\n\n\n\n\n\n\n\nThe following is the Q-Q plot of BMI.\n\nggplot(BMI_and_Gender, aes(sample = BMI)) +\n  stat_qq() +\n  stat_qq_line(color = \"red\") +\n  facet_wrap(~ Gender, scales = \"free_y\") +\n  labs(title = \"Q-Q Plot of  BMI by Gender\", x = \"Theoretical Quantiles\", y = \"Sample Quantiles\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThe data seems skewed to the right so I will plot log(BMI):\n\nhistogram_bmi &lt;- ggplot(BMI_and_Gender, aes(x = log(BMI+1), fill = Gender)) +\n  geom_histogram(binwidth = 0.1, alpha = 0.6, position = \"identity\") +  # Adjust binwidth as needed\n  facet_wrap(~ Gender, scales = \"free_y\") +  # Facet by Gender\n  labs(title = \"BMI Distribution by Gender\", x = \"BMI\", y = \"Frequency\") +\n  theme_minimal()\n\nhistogram_bmi\n\n\n\n\n\n\n\n\nThe following is the Q-Q plot of log(BMI).\n\nBMI_and_Gender$BMI_log &lt;- log(BMI_and_Gender$BMI +1)\nggplot(BMI_and_Gender, aes(sample = BMI_log)) +\n  stat_qq() +\n  stat_qq_line(color = \"red\") +\n  facet_wrap(~ Gender, scales = \"free_y\") +\n  labs(title = \"Q-Q Plot of Log-Transformed BMI by Gender\", x = \"Theoretical Quantiles\", y = \"Sample Quantiles\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nAlthough there appears to be a slight skew in the data, it generally looks appropriate to proceed with the analysis."
  },
  {
    "objectID": "dashboard/Blog.html#main-analysis-1",
    "href": "dashboard/Blog.html#main-analysis-1",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "5.3 Main analysis",
    "text": "5.3 Main analysis\nHypotheses: Null Hypothesis (H₀): There is no difference in mean BMI between genders. ( 𝜇male =𝜇female) Alternative Hypothesis (H₁): There is a difference in mean BMI between genders. (𝜇male ≠𝜇female\nChoice of Statistical Test: The decision to use an independent two-sample t-test was based on the following factors:\nThe research question aims to compare the means of BMI between two independent groups: males and females.\nThe data is continuous (BMI values) and normally distributed within each gender group, which justifies the use of a t-test. Please, refer to the dashboard to examine histograms.\nThe two-sample t-test is appropriate for comparing the means of two groups when the assumption of normality is met, and the data from each group is independent of the other.\n\nt_test_result &lt;- t.test(BMI_log ~ Gender, data = BMI_and_Gender)\nt_test_result\n\n\n    Welch Two Sample t-test\n\ndata:  BMI_log by Gender\nt = -6.2136, df = 13069, p-value = 5.335e-10\nalternative hypothesis: true difference in means between group Male and group Female is not equal to 0\n95 percent confidence interval:\n -0.04199041 -0.02185101\nsample estimates:\n  mean in group Male mean in group Female \n            3.259754             3.291675 \n\n\nThe following code back-transforms the results to make sense of it:\n\nlower_bound_backtransformed &lt;- exp(-0.04199041)\nupper_bound_backtransformed &lt;- exp(-0.02185101)\n\n# Print the back-transformed confidence interval\nlower_bound_backtransformed\n\n[1] 0.958879\n\nupper_bound_backtransformed\n\n[1] 0.978386\n\nmean_male_backtransformed &lt;- exp(3.259754)\nmean_female_backtransformed &lt;- exp(3.291675)\nmean_male_backtransformed\n\n[1] 26.04313\n\nmean_female_backtransformed\n\n[1] 26.88786"
  },
  {
    "objectID": "dashboard/Blog.html#conclusion-1",
    "href": "dashboard/Blog.html#conclusion-1",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "5.4 Conclusion",
    "text": "5.4 Conclusion\nBased on the results of the Welch Two Sample t-test, there is a statistically significant difference in the mean BMI between females and males (t = -6.2136, df = 13069, p-value = 5.335e-10). The 95% confidence interval for the difference in means between the two groups ranges from 0.958879 to 0.978386, suggesting that the true difference in log(BMI) between females and males is likely to fall within this range.\nThe back-transformed geometric mean BMI for females is 26.88786, while the mean BMI for males is26.04313. This indicates that, on average, females have a higher BMI than males in this dataset. The very small p-value (much less than 0.05) strongly supports the rejection of the null hypothesis that there is no difference in BMI between genders.\nNext Steps: Given the significant difference in BMI between genders, it may be worthwhile to further investigate potential factors that contribute to this disparity, such as age, lifestyle, or underlying health conditions. Additionally, exploring the data with different variables or additional stratifications could provide more insights into the reasons behind the observed differences."
  },
  {
    "objectID": "dashboard/Blog.html#reasoning-for-dashboard-1",
    "href": "dashboard/Blog.html#reasoning-for-dashboard-1",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "5.5 Reasoning for Dashboard",
    "text": "5.5 Reasoning for Dashboard\nMean BMI for Women and Men: The value boxes for the mean BMI of women and men were chosen to provide a quick summary of the average BMI for each gender group in the dataset. This allows users to easily compare the overall BMI levels between genders. The icons representing “gender-female” and “gender-male” along with the color choices (pink for women and blue for men) offer a clear visual distinction between the two groups. The rounding of the BMI values to two decimal places ensures the information is concise and easy to read while maintaining sufficient precision for comparison.\nBy presenting the mean BMI separately for women and men, this visualization immediately communicates the central tendency for both groups, which is useful for understanding gender-related health trends in the dataset. It is also important to highlight that the mean BMI can be used as a basic indicator of population health, and any deviations or comparisons between groups can help identify potential health issues or areas for further analysis.\nViolin Plot: The addition of a violin plot was chosen to provide a more detailed visual representation of the distribution of BMI values for both women and men. Unlike the boxplot, which only shows summary statistics (e.g., quartiles, median), the violin plot also depicts the density of the BMI distribution across genders, offering a better understanding of the data spread and potential skewness.\nThe violin plot is particularly useful for comparing the shape of the distribution between women and men, showing whether there are any differences in the variability, central tendency, or the presence of outliers in the BMI values across the two gender groups. This visualization complements the mean BMI values by giving a deeper look into the data distribution."
  },
  {
    "objectID": "dashboard/Blog.html#data-descrption-1",
    "href": "dashboard/Blog.html#data-descrption-1",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "6.1 Data Descrption",
    "text": "6.1 Data Descrption\n\n# Create the codebook table for Cholesterol and Age Groups\ndata_description_cholesterol_age &lt;- data.frame(\n  Variable_Name = c(\"Cholesterol\", \"Age_Group\"),\n  Description = c(\"Total cholesterol level (mg/dL)\",\n                  \"Age categorized into groups (e.g., 18-29, 30-39, etc.)\"),\n  Type = c(\"Quantitative\", \"Categorical\"),\n  Original_Variable_Name = c(\"LBXTC\", \"RIDAGEYR\")\n)\n\n# View the data description table\ndata_description_cholesterol_age\n\n  Variable_Name                                            Description\n1   Cholesterol                        Total cholesterol level (mg/dL)\n2     Age_Group Age categorized into groups (e.g., 18-29, 30-39, etc.)\n          Type Original_Variable_Name\n1 Quantitative                  LBXTC\n2  Categorical               RIDAGEYR\n\n\n\n# Numeric summaries for Cholesterol and Age Group\nsummary_stats_cholesterol_age &lt;- Cholesterol_AgeGroups %&gt;%\n  group_by(Age_Group)%&gt;%\n  summarise(\n    Cholesterol_Min = min(Total_Cholesterol, na.rm = TRUE),\n    Cholesterol_Max = max(Total_Cholesterol, na.rm = TRUE),\n    Cholesterol_Mean = mean(Total_Cholesterol, na.rm = TRUE),\n    Cholesterol_Median = median(Total_Cholesterol, na.rm = TRUE),\n    Cholesterol_SD = sd(Total_Cholesterol, na.rm = TRUE)\n  )\n\n# View the summary statistics for Cholesterol and Age Group\nsummary_stats_cholesterol_age\n\n# A tibble: 8 × 6\n  Age_Group Cholesterol_Min Cholesterol_Max Cholesterol_Mean Cholesterol_Median\n  &lt;fct&gt;               &lt;dbl&gt;           &lt;dbl&gt;            &lt;dbl&gt;              &lt;dbl&gt;\n1 &lt;20                    73             322             155.                153\n2 20-29                  84             416             171.                166\n3 30-39                  87             384             184.                180\n4 40-49                  84             431             193.                191\n5 50-59                  94             446             198.                195\n6 60-69                  76             365             188.                185\n7 70-79                  71             428             180.                175\n8 80+                    80             315             176.                172\n# ℹ 1 more variable: Cholesterol_SD &lt;dbl&gt;\n\nwrite.csv(Cholesterol_AgeGroups,\"CholesterolLevel_df.csv\", row.names = FALSE)\n\n\nggplot(Cholesterol_AgeGroups, aes(x = Age_Group, y = Total_Cholesterol)) +\n  geom_boxplot(fill = \"lightblue\", color = \"black\", outlier.shape = 16, outlier.colour = \"red\") +\n  theme_minimal() +\n  labs(title = \"Cholesterol Levels by Age Group\", x = \"Age Group\", y = \"Cholesterol Level\")\n\n\n\n\n\n\n\n\nIt does seem that cholesterol levels change across age groups. The data suggests that cholesterol levels peak in middle age and then decrease afterwards.\nThe following code plots a histogram for each group to examine the distribution\n\nggplot(Cholesterol_AgeGroups, aes(x = log(Total_Cholesterol))) +\n  geom_histogram(binwidth = 0.1, color = \"black\", fill = \"lightblue\", alpha = 0.7) +\n  facet_wrap(~ Age_Group, scales = \"free_y\") +  # Creates separate plots for each age group\n  theme_minimal() +\n  labs(title = \"Cholesterol Levels by Age Group\", x = \"Cholesterol Level\", y = \"Frequency\") +\n  theme(strip.text = element_text(size = 10),  # Adjusts the size of the age group labels\n        axis.text.x = element_text(angle = 45, hjust = 1))  # Rotates x-axis labels for readability\n\n\n\n\n\n\n\n\nThere seems to be some skewness in the data, so I will examine it further using a Q-Q plot.\n\nggplot(Cholesterol_AgeGroups, aes(sample = Total_Cholesterol)) +\n  stat_qq() +\n  stat_qq_line() +\n  facet_wrap(~ Age_Group) +  # Creates separate QQ plots for each age group\n  theme_minimal() +\n  labs(title = \"QQ Plots of Cholesterol Levels by Age Group\", x = \"Theoretical Quantiles\", y = \"Sample Quantiles\") +\n  theme(strip.text = element_text(size = 10),  # Adjusts the size of the age group labels\n        axis.text.x = element_text(angle = 45, hjust = 1))  # Optional: Rotates x-axis labels for readability\n\n\n\n\n\n\n\n\nAlthough the raw data appears to be reasonably close to normal, the Q-Q plot of the log-transformed data shows a much better fit, so I will proceed with the log-transformed data for a more accurate analysis\n\nggplot(Cholesterol_AgeGroups, aes(x = log(Total_Cholesterol))) +\n  geom_histogram(binwidth = 0.1, color = \"black\", fill = \"lightblue\", alpha = 0.7) +\n  facet_wrap(~ Age_Group, scales = \"free_y\") +  # Creates separate plots for each age group\n  theme_minimal() +\n  labs(title = \"Log-transformed Cholesterol Levels by Age Group\", x = \"Cholesterol Level\", y = \"Frequency\") +\n  theme(strip.text = element_text(size = 10),  # Adjusts the size of the age group labels\n        axis.text.x = element_text(angle = 45, hjust = 1))  # Rotates x-axis labels for readability\n\n\n\n\n\n\n\n\n\nggplot(Cholesterol_AgeGroups, aes(sample = log(Total_Cholesterol))) +\n  stat_qq() +\n  stat_qq_line() +\n  facet_wrap(~ Age_Group) +  # Creates separate QQ plots for each age group\n  theme_minimal() +\n  labs(title = \"QQ Plots of Cholesterol Levels by Age Group\", x = \"Theoretical Quantiles\", y = \"Sample Quantiles\") +\n  theme(strip.text = element_text(size = 10),  # Adjusts the size of the age group labels\n        axis.text.x = element_text(angle = 45, hjust = 1))  # Optional: Rotates x-axis labels for readability"
  },
  {
    "objectID": "dashboard/Blog.html#main-analysis-2",
    "href": "dashboard/Blog.html#main-analysis-2",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "6.2 Main analysis",
    "text": "6.2 Main analysis\nHypotheses: Null hypothesis (H₀): There is no significant difference in the mean cholesterol levels across the different age groups.\nAlternative hypothesis (H₁): At least one age group has a significantly different mean cholesterol level compared to the others.\nChoice of Statistical Test:\nI chose a one-way ANOVA (Analysis of Variance) to compare the cholesterol levels across multiple age groups. This test is appropriate because we are comparing the means of cholesterol levels across more than two groups (age groups), and the data appears to meet the assumptions of ANOVA. These assumptions include:\nIndependence: The cholesterol levels for each age group are independent of each other. Normality: The distribution of cholesterol levels within each age group is approximately normal. Homogeneity of variances: The variance in cholesterol levels is roughly equal across age groups.\nBefore conducting the ANOVA, I checked for outliers and ensured that the groups have approximately equal variances. If there were violations of normality or homogeneity, alternative tests or transformations would be considered.\n\n# Step 3: ANOVA test for cholesterol levels across age groups\nanova_result &lt;- aov(log(Total_Cholesterol) ~ Age_Group, data = Cholesterol_AgeGroups)\n\n# Step 4: Tukey HSD post-hoc analysis if ANOVA is significant\nsummary(anova_result)\n\n               Df Sum Sq Mean Sq F value Pr(&gt;F)    \nAge_Group       7   79.8  11.395   266.7 &lt;2e-16 ***\nResiduals   10820  462.3   0.043                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
  },
  {
    "objectID": "dashboard/Blog.html#conclusion-2",
    "href": "dashboard/Blog.html#conclusion-2",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "6.3 Conclusion",
    "text": "6.3 Conclusion\nThe results of the one-way ANOVA reveal a highly significant difference in cholesterol levels across the different age groups, with an F-value of 266.7 and a p-value of less than 2e-16. This allows us to reject the null hypothesis and conclude that there is a statistically significant difference in cholesterol levels between at least some of the age groups.\nReflection on Pre-existing Belief:\nBefore analyzing the data, there was an expectation that cholesterol levels would peak in middle age and decrease afterwards. The significant results of the ANOVA align with this expectation, indicating that age group plays a critical role in determining cholesterol levels."
  },
  {
    "objectID": "dashboard/Blog.html#reasoning-for-dashboard-2",
    "href": "dashboard/Blog.html#reasoning-for-dashboard-2",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "6.4 Reasoning for Dashboard",
    "text": "6.4 Reasoning for Dashboard\nKPIs:\nMean Cholesterol Level (mg/dL): Why this KPI?: The mean cholesterol level provides a clear, high-level summary of the overall cholesterol status of the population under study. By calculating the mean cholesterol level, you can get an idea of the average cholesterol level across all participants. Result (184.41 mg/dL): This value reflects the general cholesterol level within the study population. A mean value of 184.41 mg/dL indicates a moderate level of cholesterol, which can serve as a baseline for further analysis, such as comparing cholesterol levels across age groups or identifying trends over time. Participants with High Cholesterol (&gt;240 mg/dL): Why this KPI?: Cholesterol levels above 240 mg/dL are considered high and are associated with increased cardiovascular risk. This KPI helps track how many individuals are at risk due to elevated cholesterol levels. Result (732 participants): This value shows the number of participants whose cholesterol levels are above 240 mg/dL, allowing us to gauge the prevalence of high cholesterol in the study population. It also helps in understanding the potential burden of health conditions related to high cholesterol. Visualizations: Violin Plot of All Ages to Compare Cholesterol Distribution:\nWhy this plot?: The violin plot is effective in showing the distribution of cholesterol levels across different age groups. It provides an overview of the spread, central tendency (median), and potential outliers of cholesterol levels for the entire dataset. Insights: The plot can visually highlight trends in cholesterol levels across different ages and detect patterns such as whether cholesterol levels tend to increase with age, or if there are any age groups with especially high or low values. Interactive Histogram for Each Age Group:\nWhy this plot?: The interactive histogram allows users to drill down into cholesterol distributions within specific age groups. By making it interactive, users can filter or zoom into particular age ranges for a more detailed analysis. Insights: This histogram helps to analyze the cholesterol levels in different age groups separately. It can show how the cholesterol distribution changes with age, identify outliers, and help track whether certain age groups have a higher concentration of participants with elevated cholesterol levels.\nOverall Reasoning: By combining these KPIs and visualizations, the dashboard provides both high-level insights (mean cholesterol levels and prevalence of high cholesterol) and detailed, interactive exploration (age-specific distributions). This approach allows users to quickly grasp the general trends while also enabling deeper exploration of the data based on specific age groups.I decided to use the raw data for the dashboard to make the information more accessible and easier to interpret for a wider audience, while still considering the log-transformed data for more detailed statistical analysis in the blog.\nThis will support further analysis, such as understanding how age influences cholesterol levels and identifying key risk groups for targeted interventions or health advice."
  },
  {
    "objectID": "dashboard/Blog.html#the-question-2",
    "href": "dashboard/Blog.html#the-question-2",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "7.1 The Question",
    "text": "7.1 The Question\nI want to study the relationship between smoking status and hypertension status in a population. Specifically, I aim to understand if there is an association between smoking and the prevalence of hypertension.\nResearch Question: Is there a significant association between smoking status and hypertension status in the study population?\nPre-existing Belief: Based on existing research and common medical knowledge, I hypothesize that smokers are more likely to have hypertension compared to non-smokers. This belief stems from the understanding that smoking is a known risk factor for the development of various cardiovascular conditions, including hypertension. Therefore, I expect to find a higher percentage of smokers among the participants with hypertension."
  },
  {
    "objectID": "dashboard/Blog.html#data-descrption-2",
    "href": "dashboard/Blog.html#data-descrption-2",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "7.2 Data Descrption",
    "text": "7.2 Data Descrption\nThe following is a description of the variables we use for the analysis.\n\n# Create the codebook table for Smoking and Hypertension\ndata_description_smoking_hypertension &lt;- data.frame(\n  Variable_Name = c(\"Smoking_Status\", \"Hypertension_Status\"),\n  Description = c(\"Smoking status of the participant (Smoker/Non-Smoker)\",\n                  \"Hypertension status of the participant (Yes/No)\"),\n  Type = c(\"Categorical\", \"Categorical\"),\n  Original_Variable_Name = c(\"SMQ020\", \"BPQ020\")\n)\n\n# View the data description table\ndata_description_smoking_hypertension\n\n        Variable_Name                                           Description\n1      Smoking_Status Smoking status of the participant (Smoker/Non-Smoker)\n2 Hypertension_Status       Hypertension status of the participant (Yes/No)\n         Type Original_Variable_Name\n1 Categorical                 SMQ020\n2 Categorical                 BPQ020\n\n\nThe following are summaries of the data.\n\n# Numeric summaries for Smoking and Hypertension\nsummary_stats_smoking_hypertension &lt;- Smoking_Hypertension %&gt;%\n  group_by(Smoking_Status, Hypertension_Status) %&gt;%\n  summarise(\n    Count = n(),\n    Percentage = n() / nrow(Smoking_Hypertension) * 100,\n    .groups = \"drop\"  # This removes the grouping after summarizing\n  )\n\n# View the summary statistics for Smoking and Hypertension\nsummary_stats_smoking_hypertension\n\n# A tibble: 4 × 4\n  Smoking_Status Hypertension_Status Count Percentage\n  &lt;fct&gt;          &lt;fct&gt;               &lt;int&gt;      &lt;dbl&gt;\n1 Smoker         Yes                  1717       17.7\n2 Smoker         No                   2165       22.4\n3 Non-Smoker     Yes                  1860       19.2\n4 Non-Smoker     No                   3934       40.7\n\nwrite.csv(Smoking_Hypertension, \"smoking_hypertension_analysis_data.csv\", row.names = FALSE)\n\nThe following are the plots to examine the distribution of the data.\n\n# Bar plot for Smoking_Status\nggplot(Smoking_Hypertension, aes(x = Smoking_Status)) + \n  geom_bar() + \n  ggtitle(\"Smoking Status Distribution\")\n\n\n\n\n\n\n\n\n\n# Bar plot for Hypertension_Status\nggplot(Smoking_Hypertension, aes(x = Hypertension_Status)) + \n  geom_bar() + \n  ggtitle(\"Hypertension Status Distribution\")"
  },
  {
    "objectID": "dashboard/Blog.html#main-analysis-3",
    "href": "dashboard/Blog.html#main-analysis-3",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "7.3 Main Analysis",
    "text": "7.3 Main Analysis\nIn this analysis, we aim to investigate the relationship between smoking status and hypertension (high blood pressure) using data on participants’ smoking habits and their hypertension status. Our goal is to determine whether there is a statistically significant association between smoking and the likelihood of having hypertension. To do this, we will create a contingency table, perform a Chi-squared test, and calculate several metrics that describe the strength and direction of the association: Relative Risk (RR), Odds Ratio (OR), and Risk Difference (RD).\nStep 1: Create the Contingency Table The first step in this analysis is to create a contingency table that summarizes the counts of individuals categorized by their smoking status and their hypertension status. This table will have two key categorical variables:\nThe contingency table helps us organize the data in a way that allows us to compare the frequencies of different combinations of these two variables. Please note that Yes/NO refer to hypertensive-status.\n\n# Step 5: Create the contingency table for smoking status vs hypertension status\ncontingency_table &lt;- Smoking_Hypertension %&gt;%\n  count(Smoking_Status, Hypertension_Status) %&gt;%\n  pivot_wider(names_from = Hypertension_Status, values_from = n, values_fill = list(n = 0))\n\n# Print the contingency table\ncontingency_table\n\n# A tibble: 2 × 3\n  Smoking_Status   Yes    No\n  &lt;fct&gt;          &lt;int&gt; &lt;int&gt;\n1 Smoker          1717  2165\n2 Non-Smoker      1860  3934\n\n\nStep 2: Chi-Squared Test Once we have the contingency table, we perform a Chi-squared test to assess if there is a significant association between smoking and hypertension. The Chi-squared test is a statistical method used to determine whether two categorical variables are independent or related.\n\nchi_squared_test &lt;- chisq.test(contingency_table[, -1])\nchi_squared_test\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  contingency_table[, -1]\nX-squared = 146.2, df = 1, p-value &lt; 2.2e-16\n\n\nHere, we exclude the first column (Smoking_Status) from the contingency table, because the test requires only the counts of hypertension statuses (Yes and No) for each smoking category. T he results of the chi-square test show a significant association between the two variables, with a test statistic of X-squared = 146.2, degrees of freedom (df) = 1, and a p-value less than 2.2e-16, indicating that the relationship is highly unlikely to be due to chance.\nAfter performing the Chi-squared test, we will calculate three additional metrics: Relative Risk (RR), Odds Ratio (OR), and Risk Difference (RD). These metrics help us understand the strength and direction of the association between smoking and hypertension.\n\n# Step 7: Calculate Relative Risk (RR), Odds Ratio (OR), and Risk Difference (RD)\n# Calculate proportions for hypertensive vs non-hypertensive smokers and non-smokers\nproportions &lt;- contingency_table %&gt;%\n  mutate(\n    total = Yes + No,\n    smoker_yes = Yes / total,  # Proportion of hypertensive among smokers\n    smoker_no = No / total    # Proportion of hypertensive among non-smokers\n  )\n\n# Calculate Relative Risk (RR)\nrelative_risk &lt;- (contingency_table$Yes[1] / sum(contingency_table[1, c(\"Yes\", \"No\")])) / \n                 (contingency_table$Yes[2] / sum(contingency_table[2, c(\"Yes\", \"No\")]))\n\n# Calculate Odds Ratio (OR)\nodds_ratio &lt;- (contingency_table$Yes[1] / contingency_table$No[1]) / \n              (contingency_table$Yes[2] / contingency_table$No[2])\n\n# Calculate Risk Difference (RD)\nrisk_difference &lt;- proportions$smoker_yes[1] - proportions$smoker_yes[2]\n\n# Save the results in a data frame\nresults &lt;- data.frame(\n  Metric = c(\"Relative Risk (RR)\", \"Odds Ratio (OR)\", \"Risk Difference (RD)\"),\n  Value = c(round(relative_risk, 2), round(odds_ratio, 2), round(risk_difference, 2))\n)\n\nwrite.csv(results, \"smoking_hypertension_analysis_results.csv\", row.names = FALSE)\n\n# Print the results\nresults\n\n                Metric Value\n1   Relative Risk (RR)  1.38\n2      Odds Ratio (OR)  1.68\n3 Risk Difference (RD)  0.12"
  },
  {
    "objectID": "dashboard/Blog.html#conclusion-3",
    "href": "dashboard/Blog.html#conclusion-3",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "7.4 Conclusion",
    "text": "7.4 Conclusion\nBased on the analysis of the relationship between smoking status and hypertension, we can draw the following conclusions:\nResearch Question: The initial research question was to determine whether there is a significant association between smoking and the likelihood of having hypertension.\nChi-Squared Test Results: The Chi-squared test revealed a highly significant result with a p-value of less than 2.2e-16, which indicates that there is a very strong statistical association between smoking and hypertension. This suggests that smoking status and hypertension are not independent, and smoking is significantly associated with the likelihood of having hypertension.\nRelative Risk (RR): The Relative Risk (RR) is 1.38, which indicates that smokers are 1.38 times more likely to develop hypertension compared to non-smokers. This suggests a moderate increased risk of hypertension among smokers.\nOdds Ratio (OR): The Odds Ratio (OR) is 1.68, which means that the odds of hypertension in smokers are 1.68 times the odds of hypertension in non-smokers. This further reinforces the conclusion that smoking increases the odds of developing hypertension.\nRisk Difference (RD): The Risk Difference (RD) is 0.12, meaning that 12% more smokers have hypertension compared to non-smokers. This gives us a clear sense of the absolute difference in hypertension prevalence between smokers and non-smokers.\nImplications: The analysis strongly supports the hypothesis that smoking is associated with a higher risk of hypertension. These findings suggest that smoking may be an important modifiable risk factor for hypertension, which is a known contributor to various cardiovascular diseases. The moderate effect sizes (RR = 1.38, OR = 1.68) suggest that while smoking is a risk factor for hypertension, it is not the only factor, and other lifestyle or genetic factors may also contribute to the development of hypertension.\nLogical Next Steps: A logical next step in this analysis could be to explore the relationship between smoking, hypertension, and other potential confounders such as age, gender, physical activity, or diet. A multivariate analysis could help control for these factors and better isolate the effect of smoking on hypertension risk. Additionally, investigating the interaction between smoking and other health conditions, like diabetes or obesity, could provide further insights into the complexity of this relationship.\nReflection on Pre-Existing Beliefs:\nBefore conducting this analysis, I expected that smoking would be linked to a higher risk of hypertension, as smoking is widely known to affect cardiovascular health. The results confirm this belief with strong statistical evidence. However, the analysis also highlights the importance of considering other potential contributing factors and suggests that the risk associated with smoking, while significant, is part of a broader health context that requires further exploration."
  },
  {
    "objectID": "dashboard/Blog.html#reasoning-for-dashboard-3",
    "href": "dashboard/Blog.html#reasoning-for-dashboard-3",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "7.5 Reasoning for Dashboard",
    "text": "7.5 Reasoning for Dashboard\nThe goal of the dashboard is to visually present the key findings of the analysis regarding the association between smoking and hypertension, using key performance indicators (KPIs) and intuitive visualizations to support the data interpretation.\nKPIs: Odds Ratio (OR) = 1.68: This indicates that smokers have 1.68 times higher odds of developing hypertension compared to non-smokers. This metric is central to understanding the strength of the association between smoking and hypertension.\nRisk Difference (RD) = 12%: This indicates that 12% more smokers have hypertension than non-smokers. The RD is a straightforward measure of the absolute difference in the prevalence of hypertension between the two groups.\nVisualizations:\nStacked Bar Plot for Smoking Status and Hypertension:\nPurpose: To show the distribution of smokers and non-smokers in terms of their hypertension status. The plot will display the proportion of smokers and non-smokers who have hypertension (Yes) and who do not (No). X-axis: Smoking status (Smoker vs. Non-Smoker) Y-axis: Proportion of people in each group Stacked Bars: Each bar will be divided into segments for hypertensive and non-hypertensive individuals, allowing for a clear comparison of the two smoking groups.\nPie Chart of Hypertensive and Non-Hypertensive Participants:\nPurpose: To provide a high-level overview of the proportion of participants with and without hypertension in the entire sample. Slices: The chart will display the proportion of participants who have hypertension versus those who do not, making it easy to see the overall distribution of hypertension in the dataset. Pie Chart of Smokers and Non-Smokers:\nPurpose: To visualize the proportion of smokers versus non-smokers in the dataset. Slices: The chart will show the percentage of smokers and non-smokers, giving a sense of the prevalence of smoking in the population.\nJustification for the Visualizations: Stacked Bar Plot: This is particularly useful for comparing multiple categorical variables, such as smoking status and hypertension status. The stacked bars will allow us to easily see the relationship between smoking and hypertension in one visualization. The visual emphasis on the proportion of hypertensive individuals within each smoking group makes it clear how smoking affects the likelihood of hypertension."
  },
  {
    "objectID": "dashboard/Blog.html#my-research-question",
    "href": "dashboard/Blog.html#my-research-question",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "8.1 My Research Question",
    "text": "8.1 My Research Question\nResearch Question: How does physical activity (measured as the number of days of vigorous recreational activities per week) predict cholesterol levels, adjusting for key factors such as BMI, age, smoking status, and hypertension?\nIntroduction and Background: Cholesterol levels, particularly low-density lipoprotein (LDL) and high-density lipoprotein (HDL) cholesterol, are significant markers of cardiovascular risk. Elevated cholesterol levels, especially LDL, are associated with increased risk of heart disease, stroke, and other cardiovascular issues. Regular physical activity is widely recommended as part of lifestyle modifications to reduce cholesterol levels and improve heart health.\nDespite existing evidence supporting physical activity’s impact on cholesterol levels, there is variability in individual responses, which may depend on several other factors such as body mass index (BMI), age, smoking status, and hypertension. Understanding the interaction between physical activity and these factors is crucial for creating tailored health interventions.\nPre-analytic Hypothesis: I hypothesize that physical activity, particularly vigorous recreational activity (PAQ655), will have a negative association with cholesterol levels (lower cholesterol). I also anticipate that this relationship will be modified by other factors such as BMI, age, smoking, and hypertension. In particular, individuals with higher BMI may have less favorable cholesterol profiles despite higher levels of physical activity.\nPartitioning the Data:\nI will partition the data into two samples:\nTraining Sample: 70% of the data Test Sample: 30% of the data\nThe training sample will be used to fit the model, and the test sample will be used for model validation.\nThe following code creates a tibble that includes all the variables.\n\noriginal_data &lt;- HDL_vs_LDL %&gt;%\n  inner_join(BMI_and_Gender, by = \"SEQN\") %&gt;%\n  inner_join(Cholesterol_AgeGroups, by = \"SEQN\") %&gt;%\n  inner_join(exercise_data_clean, by = \"SEQN\") %&gt;%\n  inner_join(Smoking_Hypertension, by = \"SEQN\")\noriginal_data\n\n# A tibble: 1,000 × 27\n     SEQN   HDL   LDL   BMI Gender BMI_log Total_Cholesterol   Age Age_Group\n    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt;             &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    \n 1 109313    54    81  25.2 Male      3.27               224    63 60-69    \n 2 109326    85    70  21.6 Female    3.12               176    44 40-49    \n 3 109327    58   160  23.7 Female    3.21               203    58 50-59    \n 4 109371    60   170  29.3 Male      3.41               227    62 60-69    \n 5 109403    35   120  27.1 Male      3.34               200    30 30-39    \n 6 109426    52   103  27.9 Female    3.36               166    61 60-69    \n 7 109441    63    44  18   Female    2.94               141    20 20-29    \n 8 109444    64    36  21.7 Male      3.12               143    21 20-29    \n 9 109454    32    45  50.9 Female    3.95               126    25 20-29    \n10 109478    74    65  26.1 Female    3.30               192    27 20-29    \n# ℹ 990 more rows\n# ℹ 18 more variables: PAQ605 &lt;dbl&gt;, PAQ610 &lt;dbl&gt;, PAD615 &lt;dbl&gt;, PAQ620 &lt;dbl&gt;,\n#   PAQ625 &lt;dbl&gt;, PAD630 &lt;dbl&gt;, PAQ635 &lt;dbl&gt;, PAQ640 &lt;dbl&gt;, PAD645 &lt;dbl&gt;,\n#   PAQ650 &lt;dbl&gt;, vigorous_activity_days &lt;int&gt;, PAD660 &lt;dbl&gt;, PAQ665 &lt;dbl&gt;,\n#   PAQ670 &lt;dbl&gt;, PAD675 &lt;dbl&gt;, PAD680 &lt;dbl&gt;, Smoking_Status &lt;fct&gt;,\n#   Hypertension_Status &lt;fct&gt;"
  },
  {
    "objectID": "dashboard/Blog.html#data-description-1",
    "href": "dashboard/Blog.html#data-description-1",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "8.2 Data Description",
    "text": "8.2 Data Description\nThis code filters the data to keep only rows with complete data on key variables (cholesterol, vigorous_activity_days, BMI, age, smoking, hypertension).\n\n# Rename columns for clarity (assuming you want to use more intuitive names)\nset.seed(123) # You can pick a different seed\n\noriginal_data &lt;- original_data %&gt;%\n  filter(!is.na(Total_Cholesterol) & !is.na(vigorous_activity_days) & !is.na(BMI) & !is.na(Age_Group) & !is.na(Smoking_Status))\n\noriginal_data_cleaned &lt;- original_data %&gt;%\n  select(\n    SEQN,                            # Subject ID (always necessary)\n    Total_Cholesterol,               # Cholesterol levels\n    vigorous_activity_days,           # Vigorous activity days\n    BMI,                              # BMI\n    Age_Group,                        # Age group\n    Smoking_Status                    # Smoking status\n  )\n\noriginal_data_cleaned\n\n# A tibble: 1,000 × 6\n     SEQN Total_Cholesterol vigorous_activity_days   BMI Age_Group\n    &lt;dbl&gt;             &lt;dbl&gt;                  &lt;int&gt; &lt;dbl&gt; &lt;fct&gt;    \n 1 109313               224                      1  25.2 60-69    \n 2 109326               176                      5  21.6 40-49    \n 3 109327               203                      5  23.7 50-59    \n 4 109371               227                      3  29.3 60-69    \n 5 109403               200                      2  27.1 30-39    \n 6 109426               166                      4  27.9 60-69    \n 7 109441               141                      5  18   20-29    \n 8 109444               143                      2  21.7 20-29    \n 9 109454               126                      7  50.9 20-29    \n10 109478               192                      3  26.1 20-29    \n# ℹ 990 more rows\n# ℹ 1 more variable: Smoking_Status &lt;fct&gt;\n\n\n\n# Create a description table using reframe\ntable_description &lt;- original_data_cleaned %&gt;%\n  reframe(\n    Variable = c(\"Subject ID\", \"Total Cholesterol\", \"Vigorous Activity Days\", \"BMI\", \"Age Group\", \"Smoking Status\"),\n    Description = c(\n      \"Unique identifier for each subject\",\n      \"Total cholesterol levels (mg/dL), outcome variable\",\n      \"Number of days per week with vigorous physical activity, key predictor\",\n      \"Body Mass Index (kg/m²)\",\n      \"Age group categories (e.g., 18-24, 25-34, etc.)\",\n      \"Smoking status (e.g., smoker, non-smoker)\"\n    ),\n    Highlight = c(\"\", \"Outcome\", \"Key Indicator\", \"\", \"\", \"\")\n  )\n\n# Render table with highlights for Outcome and Key Indicator\ndatatable(table_description, \n          colnames = c(\"Variable\", \"Description\", \"Comments\"),\n          options = list(pageLength = 6)) %&gt;%\n  formatStyle(\n    'Highlight',\n    target = 'cell',\n    backgroundColor = styleEqual(c('Outcome', 'Key Indicator'), c('yellow', 'lightblue'))\n  )\n\n\n\n\n\nThe following code extracts relevant summary statistics to examine the data:\n\n# Load necessary libraries\n\n\n# Summary Statistics for Numeric Variables (BMI, Total Cholesterol, Vigorous Activity Days)\nwrite.csv(original_data_cleaned,\"study2.csv\", row.names = FALSE)\ntotal_participants &lt;- n_distinct(original_data_cleaned$SEQN)\n\nsummary_stats &lt;- original_data_cleaned %&gt;%\n  summarise(\n    Mean_BMI = mean(BMI, na.rm = TRUE),\n    SD_BMI = sd(BMI, na.rm = TRUE),\n    Min_BMI = min(BMI, na.rm = TRUE),\n    Max_BMI = max(BMI, na.rm = TRUE),\n    \n    Mean_Cholesterol = mean(Total_Cholesterol, na.rm = TRUE),\n    SD_Cholesterol = sd(Total_Cholesterol, na.rm = TRUE),\n    Min_Cholesterol = min(Total_Cholesterol, na.rm = TRUE),\n    Max_Cholesterol = max(Total_Cholesterol, na.rm = TRUE),\n    \n    Mean_Vigorous_Activity_Days = mean(vigorous_activity_days, na.rm = TRUE),\n    SD_Vigorous_Activity_Days = sd(vigorous_activity_days, na.rm = TRUE),\n    Min_Vigorous_Activity_Days = min(vigorous_activity_days, na.rm = TRUE),\n    Max_Vigorous_Activity_Days = max(vigorous_activity_days, na.rm = TRUE)\n  )\nsummary_stats_long &lt;- summary_stats %&gt;%\n  pivot_longer(\n    everything(),\n    names_to = \"Statistic\",\n    values_to = \"Value\"\n  )\n# Summary of Categorical Variables (Age Group, Smoking Status)\ncategorical_summary &lt;- original_data_cleaned %&gt;%\n  summarise(\n    Age_Group_Counts = list(table(Age_Group)),\n    Smoking_Status_Counts = list(table(Smoking_Status))\n  )\n# Create summary for categorical variables and transform them into data frames\nage_group_counts &lt;- as.data.frame(table(original_data_cleaned$Age_Group))\nnames(age_group_counts) &lt;- c(\"Age_Group\", \"Count\")\n\nsmoking_status_counts &lt;- as.data.frame(table(original_data_cleaned$Smoking_Status))\nnames(smoking_status_counts) &lt;- c(\"Smoking_Status\", \"Count\")\noriginal_data_filtered &lt;- original_data_cleaned\n# Now you can pass these data frames to plotly\n\nTotal number of Participants:\n\ntotal_participants\n\n[1] 1000\n\n\nSummary Stats:\n\nsummary_stats_long\n\n# A tibble: 12 × 2\n   Statistic                    Value\n   &lt;chr&gt;                        &lt;dbl&gt;\n 1 Mean_BMI                     28.3 \n 2 SD_BMI                        6.74\n 3 Min_BMI                      15.5 \n 4 Max_BMI                      82   \n 5 Mean_Cholesterol            180.  \n 6 SD_Cholesterol               39.9 \n 7 Min_Cholesterol              76   \n 8 Max_Cholesterol             370   \n 9 Mean_Vigorous_Activity_Days   3.39\n10 SD_Vigorous_Activity_Days     1.53\n11 Min_Vigorous_Activity_Days    1   \n12 Max_Vigorous_Activity_Days    7   \n\nage_group_counts\n\n  Age_Group Count\n1       &lt;20    97\n2     20-29   259\n3     30-39   188\n4     40-49   175\n5     50-59   136\n6     60-69    92\n7     70-79    39\n8       80+    14\n\n\nNote: Please note that all the data has been cleaned in an earlier section of this blog post, so I will proceed with the rest of the analysis.\n\n# Descriptive statistics for continuous variables\nsummary_stats_continuous &lt;- original_data_filtered %&gt;%\n  select(Total_Cholesterol, vigorous_activity_days, BMI) %&gt;%\n  summary()\n\n# Descriptive statistics for categorical variables (Age_Group, smoking_status)\nsummary_stats_categorical &lt;- original_data_filtered %&gt;%\n  select(Age_Group, Smoking_Status) %&gt;%\n  summarise(\n    Age_Group_counts = list(table(Age_Group)),\n    Smoking_status_counts = list(table(Smoking_Status))\n  )"
  },
  {
    "objectID": "dashboard/Blog.html#partitioning-the-data",
    "href": "dashboard/Blog.html#partitioning-the-data",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "8.3 Partitioning the Data",
    "text": "8.3 Partitioning the Data\nThe following code splits the data to a training and a test set.\n\n# Set a random seed to ensure reproducibility of the split\nset.seed(123) \n\ntraining_sample &lt;- original_data_filtered %&gt;%\n  slice_sample(prop = 0.70)\n\ntest_sample &lt;- anti_join(original_data_filtered, training_sample, by = \"SEQN\")\n\n# Verify that the split is correct\ncat(\"Training Sample Size:\", nrow(training_sample), \"\\n\")\n\nTraining Sample Size: 700 \n\ncat(\"Test Sample Size:\", nrow(test_sample), \"\\n\")\n\nTest Sample Size: 300 \n\nall_subjects &lt;- union(training_sample$SEQN, test_sample$SEQN)\n\n# Ensure that the number of unique subjects matches the original dataset\nif (length(all_subjects) == nrow(original_data_filtered)) {\n  cat(\"All subjects are accounted for in the training and test samples.\\n\")\n} else {\n  cat(\"Some subjects are missing or duplicated in the training and test samples.\\n\")\n}\n\nAll subjects are accounted for in the training and test samples.\n\n\nThe following code plots the outcome variables to examine the data and its normality.\n\n# Visualize the distribution of cholesterol levels using a histogram\nggplot(training_sample, aes(x = Total_Cholesterol)) +\n  geom_histogram(binwidth = 0.5, fill = \"blue\", color = \"black\", alpha = 0.7) +\n  labs(title = \"Distribution of Cholesterol Levels\", x = \"Cholesterol Levels\", y = \"Frequency\") +\n  theme_minimal()\n\n\n\n\n\n\n\nggplot(training_sample, aes(sample = (Total_Cholesterol))) +\n  geom_qq() +\n  geom_qq_line() +\n  labs(title = \"Q-Q Plot for Cholesterol Levels\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThe distribution appears asymmetric and almost normal, so I believe a square root transformation would be a better approach to improve normality and stabilize variance.\n\n# Visualize the distribution of cholesterol levels using a histogram\nggplot(training_sample, aes(x = sqrt(Total_Cholesterol))) +\n  geom_histogram(binwidth = 0.8, fill = \"blue\", color = \"black\", alpha = 0.7) +\n  labs(title = \"Distribution of Cholesterol Levels\", x = \"Cholesterol Levels\", y = \"Frequency\") +\n  theme_minimal()\n\n\n\n\n\n\n\nggplot(training_sample, aes(sample = log(Total_Cholesterol))) +\n  geom_qq() +\n  geom_qq_line() +\n  labs(title = \"Q-Q Plot for Cholesterol Levels\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nI will proceed with the square root transformed data for further analysis."
  },
  {
    "objectID": "dashboard/Blog.html#the-big-model",
    "href": "dashboard/Blog.html#the-big-model",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "8.4 The Big Model",
    "text": "8.4 The Big Model\nThe following code builds the linear regression model.\n\n# Fit the full model (including all predictors)\nfull_model &lt;- lm(sqrt(Total_Cholesterol) ~ vigorous_activity_days + BMI + Age_Group + Smoking_Status, data = training_sample)\n\n# Summarize the full model\nsummary(full_model)\n\n\nCall:\nlm(formula = sqrt(Total_Cholesterol) ~ vigorous_activity_days + \n    BMI + Age_Group + Smoking_Status, data = training_sample)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.0547 -0.8770 -0.0493  0.7757  4.2901 \n\nCoefficients:\n                          Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)              12.635348   0.312309  40.458  &lt; 2e-16 ***\nvigorous_activity_days   -0.025869   0.033979  -0.761  0.44672    \nBMI                      -0.012491   0.007825  -1.596  0.11088    \nAge_Group20-29            0.889587   0.197795   4.498 8.07e-06 ***\nAge_Group30-39            1.444715   0.207615   6.959 8.01e-12 ***\nAge_Group40-49            1.666069   0.211028   7.895 1.15e-14 ***\nAge_Group50-59            1.579022   0.224690   7.028 5.06e-12 ***\nAge_Group60-69            1.552336   0.248903   6.237 7.79e-10 ***\nAge_Group70-79            0.908129   0.324803   2.796  0.00532 ** \nAge_Group80+              0.812359   0.516529   1.573  0.11624    \nSmoking_StatusNon-Smoker -0.031346   0.114507  -0.274  0.78436    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.374 on 689 degrees of freedom\nMultiple R-squared:  0.1183,    Adjusted R-squared:  0.1055 \nF-statistic: 9.248 on 10 and 689 DF,  p-value: 1.858e-14\n\n# Tidy the model to extract coefficients and other statistics\ntidy_full_model &lt;- tidy(full_model)\ntidy_full_model\n\n# A tibble: 11 × 5\n   term                     estimate std.error statistic   p.value\n   &lt;chr&gt;                       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n 1 (Intercept)               12.6      0.312      40.5   3.46e-184\n 2 vigorous_activity_days    -0.0259   0.0340     -0.761 4.47e-  1\n 3 BMI                       -0.0125   0.00782    -1.60  1.11e-  1\n 4 Age_Group20-29             0.890    0.198       4.50  8.07e-  6\n 5 Age_Group30-39             1.44     0.208       6.96  8.01e- 12\n 6 Age_Group40-49             1.67     0.211       7.90  1.15e- 14\n 7 Age_Group50-59             1.58     0.225       7.03  5.06e- 12\n 8 Age_Group60-69             1.55     0.249       6.24  7.79e- 10\n 9 Age_Group70-79             0.908    0.325       2.80  5.32e-  3\n10 Age_Group80+               0.812    0.517       1.57  1.16e-  1\n11 Smoking_StatusNon-Smoker  -0.0313   0.115      -0.274 7.84e-  1\n\n\nThe linear regression model results suggest several important findings related to significant predictors and model fit.\nSignificant Predictors:\nAge Group: Age appears to be a significant predictor of the outcome variable, with all age groups (20-29, 30-39, 40-49, 50-59, 60-69, and 70-79) showing statistically significant positive associations with the outcome (p-values &lt; 0.05). Specifically, individuals in the age groups 20-29, 30-39, 40-49, 50-59, and 60-69 have significantly higher outcome values compared to the baseline group (presumably those under 20). The effect for the 70-79 age group is also significant, though with a smaller coefficient estimate. However, the 80+ age group was not significant (p = 0.11624), suggesting diminishing returns for older age groups. Vigorous Activity, BMI, and Smoking Status: Neither vigorous activity days, BMI, nor smoking status were found to be significant predictors of the outcome, with p-values of 0.447, 0.111, and 0.784, respectively. This suggests that these variables do not have a strong influence on the outcome after controlling for other factors. Model Fit:\nResiduals: The residuals range from -5.05 to 4.29, with a median near zero (-0.0493), suggesting a reasonably symmetric distribution of errors. The interquartile range is 0.88, indicating moderate variability in the residuals. R-squared and Adjusted R-squared: The model has a multiple R-squared of 0.1183 and an adjusted R-squared of 0.1055, indicating that only about 11.8% of the variance in the outcome is explained by the predictors. While this is relatively low, the model still provides useful insight into the relationship between age and the outcome variable. The adjusted R-squared suggests that, after accounting for the number of predictors in the model, the fit remains modest. F-statistic and p-value: The F-statistic is 9.248, with a p-value of 1.858e-14, indicating that the model as a whole is statistically significant and provides a better fit than an intercept-only model."
  },
  {
    "objectID": "dashboard/Blog.html#the-smaller-model",
    "href": "dashboard/Blog.html#the-smaller-model",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "8.5 The Smaller Model",
    "text": "8.5 The Smaller Model\nThe following code implements a subset model using the key predictor, and Age_group.\n\n# Fit the subset model (including the key predictor and other important variables)\nsubset_model &lt;- lm(sqrt(Total_Cholesterol) ~ vigorous_activity_days + Age_Group, data = training_sample)\n\n# Summarize the subset model\nsummary(subset_model)\n\n\nCall:\nlm(formula = sqrt(Total_Cholesterol) ~ vigorous_activity_days + \n    Age_Group, data = training_sample)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.0436 -0.8984 -0.0769  0.8001  4.2519 \n\nCoefficients:\n                       Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)            12.27689    0.20725  59.237  &lt; 2e-16 ***\nvigorous_activity_days -0.02450    0.03389  -0.723  0.47001    \nAge_Group20-29          0.87386    0.19563   4.467 9.26e-06 ***\nAge_Group30-39          1.42659    0.20576   6.933 9.46e-12 ***\nAge_Group40-49          1.63137    0.20840   7.828 1.86e-14 ***\nAge_Group50-59          1.54645    0.22204   6.965 7.67e-12 ***\nAge_Group60-69          1.53349    0.24347   6.299 5.35e-10 ***\nAge_Group70-79          0.90726    0.32254   2.813  0.00505 ** \nAge_Group80+            0.80880    0.51468   1.571  0.11653    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.375 on 691 degrees of freedom\nMultiple R-squared:  0.115, Adjusted R-squared:  0.1048 \nF-statistic: 11.23 on 8 and 691 DF,  p-value: 5.255e-15\n\n# Tidy the model to extract coefficients and other statistics\ntidy_subset_model &lt;- tidy(subset_model)\ntidy_subset_model\n\n# A tibble: 9 × 5\n  term                   estimate std.error statistic   p.value\n  &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)             12.3       0.207     59.2   5.36e-273\n2 vigorous_activity_days  -0.0245    0.0339    -0.723 4.70e-  1\n3 Age_Group20-29           0.874     0.196      4.47  9.26e-  6\n4 Age_Group30-39           1.43      0.206      6.93  9.46e- 12\n5 Age_Group40-49           1.63      0.208      7.83  1.86e- 14\n6 Age_Group50-59           1.55      0.222      6.96  7.67e- 12\n7 Age_Group60-69           1.53      0.243      6.30  5.35e- 10\n8 Age_Group70-79           0.907     0.323      2.81  5.05e-  3\n9 Age_Group80+             0.809     0.515      1.57  1.17e-  1\n\n\nThe results of the subset linear regression model, where the outcome variable is the square root of total cholesterol, reveal several key findings about the significant predictors and overall model fit.\nSignificant Predictors:\nAge Group: Similar to the previous model, age is a significant predictor of the outcome variable. All age groups, except for the 80+ group, show significant positive associations with total cholesterol (p-values &lt; 0.05). The 20-29, 30-39, 40-49, 50-59, 60-69, and 70-79 age groups all have significantly higher cholesterol levels compared to the baseline group (presumably under 20). The 80+ group was not significant (p = 0.11653), suggesting that the effect of age plateaus at older ages. Vigorous Activity: Vigorous activity days was not a significant predictor in this model (p = 0.47001), indicating that the amount of vigorous activity does not have a meaningful relationship with cholesterol levels after controlling for age group. Model Fit:\nResiduals: The residuals range from -5.04 to 4.25, with a median of -0.0769, indicating a relatively symmetric distribution of errors. The interquartile range is 0.90, suggesting moderate variability in the residuals. R-squared and Adjusted R-squared: The multiple R-squared for the model is 0.115, and the adjusted R-squared is 0.1048, meaning the model explains approximately 11.5% of the variance in cholesterol levels. This is a modest fit, similar to the full model, suggesting that other unexamined factors could play a role in explaining cholesterol variation. The adjusted R-squared indicates that, after considering the number of predictors, the fit is still modest. F-statistic and p-value: The F-statistic is 11.23 with a p-value of 5.255e-15, which indicates that the model is statistically significant and provides a better fit than an intercept-only model."
  },
  {
    "objectID": "dashboard/Blog.html#in-sample-comparison",
    "href": "dashboard/Blog.html#in-sample-comparison",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "8.6 In-Sample Comparison",
    "text": "8.6 In-Sample Comparison\n\n8.6.1 Quality of Fit\nThe following is comparison of key information about both models.\n\n# Evaluate the full model\nfull_model_r2 &lt;- summary(full_model)$r.squared\nfull_model_adj_r2 &lt;- summary(full_model)$adj.r.squared\nfull_model_rmse &lt;- sqrt(mean(residuals(full_model)^2))\n\n# Evaluate the subset model\nsubset_model_r2 &lt;- summary(subset_model)$r.squared\nsubset_model_adj_r2 &lt;- summary(subset_model)$adj.r.squared\nsubset_model_rmse &lt;- sqrt(mean(residuals(subset_model)^2))\n# Calculate AIC and BIC for both models\nfull_model_aic &lt;- AIC(full_model)\nsubset_model_aic &lt;- AIC(subset_model)\n\nfull_model_bic &lt;- BIC(full_model)\nsubset_model_bic &lt;- BIC(subset_model)\n# Print comparison\ncomparison &lt;- tibble(\n  Model = c(\"Full Model\", \"Subset Model\"),\n  R_squared = c(full_model_r2, subset_model_r2),\n  Adjusted_R_squared = c(full_model_adj_r2, subset_model_adj_r2),\n  RMSE = c(full_model_rmse, subset_model_rmse),\n  AIC = c(full_model_aic,subset_model_aic),\n  BIC = c(full_model_bic,subset_model_bic)\n)\n\ncomparison\n\n# A tibble: 2 × 6\n  Model        R_squared Adjusted_R_squared  RMSE   AIC   BIC\n  &lt;chr&gt;            &lt;dbl&gt;              &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Full Model       0.118              0.106  1.36 2445. 2499.\n2 Subset Model     0.115              0.105  1.37 2443. 2489.\n\nwrite_csv(comparison, \"model_comparison.csv\")\n\n\n\n8.6.2 Posterior Predictive Checks\nFor each model, we will generate predictions using the model’s coefficients and residuals. These predictions can then be compared with the observed data.\n\nsimulated_full_model &lt;- simulate(full_model, nsim = 1000)  # Simulate 1000 datasets\n\n# Simulate from the subset model\nsimulated_subset_model &lt;- simulate(subset_model, nsim = 1000)  # Simulate 1000 datasets\n\n# Extract observed data (original values)\nobserved_data &lt;- sqrt(training_sample$Total_Cholesterol)  # Replace with your actual response variable\nsim_full_data &lt;- simulated_full_model[[1]]  # First simulated dataset\nsim_subset_data &lt;- simulated_subset_model[[1]]  # First simulated dataset\n\n# Create a data frame for ggplot\nobserved_df &lt;- data.frame(Value = observed_data, Type = \"Observed\")\nsim_full_df &lt;- data.frame(Value = sim_full_data, Type = \"Simulated Full Model\")\nsim_subset_df &lt;- data.frame(Value = sim_subset_data, Type = \"Simulated Subset Model\")\n\n# Combine the data frames\ncombined_df &lt;- rbind(observed_df, sim_full_df, sim_subset_df)\n\n# Plot the histograms using ggplot2\nlibrary(ggplot2)\n\n# Histogram for Full Model\nggplot(combined_df, aes(x = Value, fill = Type)) +\n  geom_histogram(alpha = 0.5, position = \"identity\", bins = 30, color = \"black\") +\n  scale_fill_manual(values = c(\"lightblue\", \"red\", \"green\")) +\n  labs(title = \"Full Model: Observed vs Simulated\", x = \"Total Cholesterol\", y = \"Frequency\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# Q-Q plot for Full Model\nggplot() +\n  stat_qq(data = data.frame(Value = observed_data), aes(sample = Value), color = \"blue\") +\n  stat_qq_line(data = data.frame(Value = observed_data), aes(sample = Value), color = \"blue\") +\n  stat_qq(data = data.frame(Value = sim_full_data), aes(sample = Value), color = \"red\") +\n  stat_qq_line(data = data.frame(Value = sim_full_data), aes(sample = Value), color = \"red\") +\n  labs(title = \"Q-Q Plot: Full Model\", x = \"Theoretical Quantiles\", y = \"Sample Quantiles\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# Q-Q plot for Subset Model\nggplot() +\n  stat_qq(data = data.frame(Value = observed_data), aes(sample = Value), color = \"blue\") +\n  stat_qq_line(data = data.frame(Value = observed_data), aes(sample = Value), color = \"blue\") +\n  stat_qq(data = data.frame(Value = sim_subset_data), aes(sample = Value), color = \"red\") +\n  stat_qq_line(data = data.frame(Value = sim_subset_data), aes(sample = Value), color = \"red\") +\n  labs(title = \"Q-Q Plot: Subset Model\", x = \"Theoretical Quantiles\", y = \"Sample Quantiles\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nWhen examining the posterior predictive checks for both the full and subset models, there appear to be systematic discrepancies between the observed and simulated data, particularly in the middle of the distribution. In both models, the simulated data does not align closely with the observed data, showing noticeable gaps in the middle range of cholesterol values. This suggests that the models might not fully capture the central tendencies of the observed data. Specifically, the simulated values tend to deviate from the observed values around the median, indicating that both models may be overestimating or underestimating the cholesterol levels in this region. This discrepancy points to potential limitations in the model structure, such as the choice of predictors or the functional form of the model. Further refinement or alternative modeling approaches may be necessary to better fit the observed data, particularly in the central range of the outcome variable.\n\n\n8.6.3 Assessing Assumptions,\n\n# 1. Residual vs. Fitted Plot\npar(mfrow = c(1, 2))  # Set up a 1x2 grid for the plots\n# Residual vs Fitted for subset_model\nplot(subset_model$fitted.values, residuals(subset_model), \n     xlab = \"Fitted Values\", ylab = \"Residuals\", \n     main = \"Residual vs Fitted (Subset Model)\", pch = 16)\nabline(h = 0, col = \"red\")\n# Residual vs Fitted for full_model\nplot(full_model$fitted.values, residuals(full_model), \n     xlab = \"Fitted Values\", ylab = \"Residuals\", \n     main = \"Residual vs Fitted (Full Model)\", pch = 16)\nabline(h = 0, col = \"red\")\n\n\n\n\n\n\n\n# 2. Q-Q Plot to check Normality of Residuals\npar(mfrow = c(1, 2))  # Set up a 1x2 grid for the plots\n# Q-Q Plot for subset_model\nqqnorm(residuals(subset_model), main = \"Q-Q Plot (Subset Model)\")\nqqline(residuals(subset_model), col = \"red\")\n# Q-Q Plot for full_model\nqqnorm(residuals(full_model), main = \"Q-Q Plot (Full Model)\")\nqqline(residuals(full_model), col = \"red\")\n\n\n\n\n\n\n\n# 3. Histogram of Residuals\npar(mfrow = c(1, 2))  # Set up a 1x2 grid for the plots\n# Histogram for subset_model\nhist(residuals(subset_model), main = \"Histogram of Residuals (Subset Model)\", \n     xlab = \"Residuals\", col = \"lightblue\", breaks = 20)\n# Histogram for full_model\nhist(residuals(full_model), main = \"Histogram of Residuals (Full Model)\", \n     xlab = \"Residuals\", col = \"lightgreen\", breaks = 20)\n\n\n\n\n\n\n\n# 4. Cook's Distance Plot to check for Influential Points\npar(mfrow = c(1, 2))  # Set up a 1x2 grid for the plots\n# Cook's Distance for subset_model\nplot(cooks.distance(subset_model), type = \"h\", main = \"Cook's Distance (Subset Model)\", \n     ylab = \"Cook's Distance\", xlab = \"Index\")\nabline(h = 1, col = \"red\")\n# Cook's Distance for full_model\nplot(cooks.distance(full_model), type = \"h\", main = \"Cook's Distance (Full Model)\", \n     ylab = \"Cook's Distance\", xlab = \"Index\")\nabline(h = 1, col = \"red\")# 4. Cook's Distance Plot to check for Influential Points\n\n\n\n\n\n\n\npar(mfrow = c(1, 2))  # Set up a 1x2 grid for the plots\n# Cook's Distance for subset_model\nplot(cooks.distance(subset_model), type = \"h\", main = \"Cook's Distance (Subset Model)\", \n     ylab = \"Cook's Distance\", xlab = \"Index\")\nabline(h = 1, col = \"red\")\n# Cook's Distance for full_model\nplot(cooks.distance(full_model), type = \"h\", main = \"Cook's Distance (Full Model)\", \n     ylab = \"Cook's Distance\", xlab = \"Index\")\nabline(h = 1, col = \"red\")\n\n\n\n\n\n\n\n# Reset plotting layout\npar(mfrow = c(1, 1))\n\n# Create combined diagnostic plots for subset and full models\n\nThe residual vs. fitted plots for both models indicate that the assumption of linearity is reasonably met, as there is no clear pattern in the residuals, though some clustering around certain fitted values suggests potential structure in the data. However, the assumption of constant variance (homoscedasticity) appears slightly violated, with some residuals showing greater spread at specific ranges of fitted values. The Q-Q plots reveal that the residuals mostly follow the expected normal distribution, adhering well to the diagonal line for most quantiles. Nonetheless, deviations at the tails, particularly in the full model, suggest potential issues with outliers or non-normality in the extremes. The Cook’s Distance plots for both the Full Model and Subset Model reveal that most data points have minimal influence, as indicated by low Cook’s Distance values, while a few points stand out as potentially influential. The Full Model, which includes predictors such as the number of vigorous activity days, the square root of BMI, age group, and smoking status, shows slightly higher Cook’s Distance values for some observations compared to the Subset Model, which excludes smoking status. This suggests that including smoking status might amplify the influence of certain data points, possibly due to interaction effects or multicollinearity with other predictors. Both models identify similar influential observations, indicating consistency in the data’s behavior. While these minor violations might not significantly impact the model’s overall validity, further investigation of the outliers and potential transformations could improve the model’s assumptions and robustness.\n\n\n8.6.4 Comparing the Models\nStrengths and Weaknesses Goodness of Fit and Predictive Performance:\nThe full model has a slightly higher R² (0.118 vs. 0.115) and adjusted R² (0.106 vs. 0.105), as well as a marginally lower RMSE (1.363 vs. 1.366). However, these differences are minimal, suggesting little improvement from including additional predictors. Both models exhibit systematic discrepancies in posterior predictive checks, particularly around the median cholesterol values, indicating that neither fully captures central tendencies. Model Complexity and Penalization:\nThe subset model has lower AIC (2443.17 vs. 2444.55) and BIC (2488.69 vs. 2499.17), suggesting better parsimony and generalization. Assumptions:\nBoth models meet linearity assumptions reasonably well but show slight heteroscedasticity in residuals. Q-Q plots reveal alignment with normality for most quantiles, but deviations at the tails, more pronounced in the full model, suggest issues with outliers or extreme values. Preferred Model The subset model is preferable due to its lower AIC, BIC, and comparable performance to the full model, making it a simpler and more generalizable choice. While both models share limitations in posterior predictive checks, the subset model strikes a better balance between simplicity and predictive accuracy.\nThe following plot summerizes key metrics.\n\n# Create a data frame for the model performance metrics\nmodel_metrics &lt;- data.frame(\n  Metric = c(\"R²\", \"Adjusted R²\", \"RMSE\", \"AIC\", \"BIC\"),\n  Full_Model = c(0.1183343, 0.1055380, 1.363464, 2444.554, 2499.167),\n  Subset_Model = c(0.1150278, 0.1047821, 1.366019, 2443.174, 2488.685)\n)\n\n# Reshape the data for ggplot (long format)\nmodel_metrics_long &lt;- model_metrics %&gt;%\n  gather(key = \"Model\", value = \"Value\", -Metric)\n\n# Log transform the metrics with large scale (AIC, BIC)\nmodel_metrics_long$Log_Value &lt;- ifelse(model_metrics_long$Metric %in% c(\"AIC\", \"BIC\"), \n                                       log(model_metrics_long$Value), \n                                       model_metrics_long$Value)\n\n# Create the plot\nggplot(model_metrics_long, aes(x = Metric, y = Log_Value, fill = Model)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  scale_y_continuous(labels = scales::comma_format(), \n                     sec.axis = sec_axis(~ ., breaks = log(c(1000, 10000, 100000)), labels = c(1000, 10000, 100000))) +\n  labs(title = \"Comparison of Model Performance Metrics\", \n       x = \"Metric\", \n       y = \"Log-Transformed Value\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n  scale_fill_manual(values = c(\"Full_Model\" = \"steelblue\", \"Subset_Model\" = \"lightgreen\"))"
  },
  {
    "objectID": "dashboard/Blog.html#model-validation",
    "href": "dashboard/Blog.html#model-validation",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "8.7 Model Validation",
    "text": "8.7 Model Validation\n\n8.7.1 Calculating Prediction Errors\nThis code applies both model on the test_sample and does the back-tranformation.\n\npred_full_model &lt;- predict(full_model, newdata = test_sample)\npred_subset_model &lt;- predict(subset_model, newdata = test_sample)\n\n# Back-transform the predictions (since we applied log transformation, we need to exponentiate the predictions)\nback_transformed_pred_full &lt;- pred_full_model^2\nback_transformed_pred_subset &lt;- pred_subset_model^2\n\n# Add the predictions (back-transformed) to the test_sample data frame\ntest_sample$Pred_Full_Model &lt;- back_transformed_pred_full\ntest_sample$Pred_Subset_Model &lt;- back_transformed_pred_subset\n\n# View the test sample with predictions\nhead(test_sample)\n\n# A tibble: 6 × 8\n    SEQN Total_Cholesterol vigorous_activity_days   BMI Age_Group Smoking_Status\n   &lt;dbl&gt;             &lt;dbl&gt;                  &lt;int&gt; &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt;         \n1 109313               224                      1  25.2 60-69     Non-Smoker    \n2 109327               203                      5  23.7 50-59     Non-Smoker    \n3 109371               227                      3  29.3 60-69     Non-Smoker    \n4 109441               141                      5  18   20-29     Non-Smoker    \n5 109454               126                      7  50.9 20-29     Non-Smoker    \n6 109503               152                      3  27.4 70-79     Smoker        \n# ℹ 2 more variables: Pred_Full_Model &lt;dbl&gt;, Pred_Subset_Model &lt;dbl&gt;\n\n\n\n\n8.7.2 Visualizing the Predictions\nThe following plot visualizes the prediction and observed data.\n\n# Create a combined data frame for the observed vs predicted values for both models\nvisualization_data &lt;- test_sample %&gt;%\n  select(Total_Cholesterol, Pred_Full_Model, Pred_Subset_Model) %&gt;%\n  gather(key = \"Model\", value = \"Predicted\", -Total_Cholesterol)\n\n# Create the plot\nggplot(visualization_data, aes(x = Predicted, y = Total_Cholesterol, color = Model)) +\n  geom_point(alpha = 0.6) +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"black\") + # Line for observed = predicted\n  theme_minimal() +\n  labs(\n    title = \"Predicted vs Observed Cholesterol Levels\",\n    x = \"Predicted Cholesterol Level\",\n    y = \"Observed Cholesterol Level\",\n    color = \"Model\"\n  ) +\n  theme(legend.position = \"top\") +\n  scale_color_manual(values = c(\"blue\", \"red\"))\n\n\n\n\n\n\n\n\n\n\n8.7.3 Summarizing the Errors\nThe following code summarizes infromation about the models.\n\n# Compute the errors for the full model\ntest_sample$Predicted_Full_Model &lt;- predict(full_model, newdata = test_sample)\ntest_sample$Predicted_Subset_Model &lt;- predict(subset_model, newdata = test_sample)\n\n# Back-transformation (square root)\ntest_sample$Actual_Total_Cholesterol &lt;- test_sample$Total_Cholesterol^2\n\n# Full Model Errors\nfull_model_residuals &lt;- test_sample$Actual_Total_Cholesterol - test_sample$Predicted_Full_Model^2\nfull_model_rmspe &lt;- sqrt(mean(full_model_residuals^2))\nfull_model_mape &lt;- mean(abs(full_model_residuals / test_sample$Actual_Total_Cholesterol))\nfull_model_mae &lt;- max(abs(full_model_residuals))\nfull_model_r_squared &lt;- cor(test_sample$Actual_Total_Cholesterol, test_sample$Predicted_Full_Model)^2\n\n# Subset Model Errors\nsubset_model_residuals &lt;- test_sample$Actual_Total_Cholesterol - test_sample$Predicted_Subset_Model^2\nsubset_model_rmspe &lt;- sqrt(mean(subset_model_residuals^2))\nsubset_model_mape &lt;- mean(abs(subset_model_residuals / test_sample$Actual_Total_Cholesterol))\nsubset_model_mae &lt;- max(abs(subset_model_residuals))\nsubset_model_r_squared &lt;- cor(test_sample$Actual_Total_Cholesterol, test_sample$Predicted_Subset_Model)^2\n\n# Combine the results into a table\nerror_summary &lt;- data.frame(\n  Metric = c(\"RMSPE\", \"MAPE\", \"MAE\", \"Squared Correlation\"),\n  Full_Model = c(full_model_rmspe, full_model_mape, full_model_mae, full_model_r_squared),\n  Subset_Model = c(subset_model_rmspe, subset_model_mape, subset_model_mae, subset_model_r_squared)\n)\n\n# Print the error summary table\nkable(error_summary, caption = \"Model Performance Error Metrics\")\n\n\nModel Performance Error Metrics\n\n\nMetric\nFull_Model\nSubset_Model\n\n\n\n\nRMSPE\n3.677902e+04\n3.677900e+04\n\n\nMAPE\n9.935081e-01\n9.935029e-01\n\n\nMAE\n1.367273e+05\n1.367281e+05\n\n\nSquared Correlation\n8.284200e-02\n8.038260e-02\n\n\n\n\n\n\n\n8.7.4 Comparing the Models\nObservations from the Metrics: RMSPE and MAE: Both models have almost identical RMSPE and MAE values, suggesting that the models have very similar prediction errors, regardless of which model is used. This indicates that the overall magnitude of prediction errors for both models is comparable.\nMAPE: The MAPE values for both models are extremely close (0.9935), meaning that the percentage error between predicted and observed values is nearly identical for both models.\nSquared Correlation (R²): Both models exhibit low squared correlation, with the full model performing slightly better (0.0828 vs. 0.0804). However, neither model has a high R², indicating that the models do not explain much of the variance in the observed cholesterol levels.\nVisual Comparison: The scatter plot you uploaded illustrates the relationship between the observed and predicted cholesterol levels for both models. Here are some insights from the plot:\nGeneral Trend: Both models seem to predict similar ranges of cholesterol values, but neither model perfectly matches the observed values, especially for the higher cholesterol levels. The line showing “observed = predicted” (the dashed line) is not closely matched by the points, indicating a relatively weak model fit.\nClustering and Spread: Both the full model (blue) and the subset model (red) show some clustering of points near the lower predicted values (around 150-160), with a wider spread as the predicted values increase. This suggests that both models are somewhat conservative in predicting higher cholesterol levels.\nConclusion: While both models have nearly identical performance metrics and display similar trends in the scatter plot, the full model may have a slight edge due to its marginally better squared correlation. However, the low R² for both models suggests that there may be a need for further refinement or alternative modeling techniques. Based on these results, I would prefer the full model, but with the understanding that neither model is particularly strong in explaining the variance in the outcome. Both models could benefit from further exploration or adjustments."
  },
  {
    "objectID": "dashboard/Blog.html#discussion",
    "href": "dashboard/Blog.html#discussion",
    "title": "Cardiovascular Risk Factors: Examining Cardiovascular risk Using NHANES Pre-Pandemic Data",
    "section": "8.8 Discussion",
    "text": "8.8 Discussion\n\n8.8.1 Chosen Model\nBased on the results, I would choose the Full Model for further analysis, and here’s why:\nSlightly Better Performance Metrics: The Full Model has a marginally better squared correlation (0.0828 vs. 0.0804) compared to the Subset Model. While the difference is small, every bit of improvement in model fit could lead to better predictive performance, especially when dealing with more complex datasets.\nMore Predictive Power: Although both models have similar RMSPE, MAPE, and MAE values, the Full Model slightly outperforms the Subset Model in terms of fitting the observed data. Even though the difference isn’t huge, the small improvement could still make a meaningful difference in practice.\nModel Complexity: The Full Model likely incorporates more features, which, while introducing more complexity, also potentially captures more nuances in the data. If the Full Model includes key predictors that the Subset Model lacks, this might help explain certain aspects of the outcome better than the simpler model.\n\n\n8.8.2 Answering My Question\nThe research question asks: How does physical activity (measured as the number of days of vigorous recreational activities per week) predict cholesterol levels, adjusting for key factors such as BMI, age, smoking status, and hypertension?\nBased on the results from the full model, which included all the key predictors (vigorous activity, BMI, age group, smoking status), we can make the following conclusions:\nThe model explains approximately 11.36% of the variance in cholesterol levels in the training sample. This means that, while the full model offers some predictive power, a substantial portion of cholesterol levels’ variability remains unexplained by these factors alone.\nVigorous activity (number of days per week) did not appear to be a strong predictor of cholesterol levels in the full model, as evidenced by the relatively low R-squared value. The model also showed modest performance when validated on the test sample (R-squared = 8.3%), suggesting that it may not generalize well.\nKey predictors such as BMI, age, smoking status, and hypertension did not provide much additional explanatory power to cholesterol levels in the context of this model.\nThis suggests that physical activity, as captured by the number of days of vigorous recreational activities, may not be the primary driver of cholesterol levels when adjusted for the other variables in this dataset. Other factors, possibly unmeasured or more complex interactions, might be playing a significant role.\nLimitations of the Study:\nModel Fit and Predictive Power:\nThe low R-squared values (both in-sample and out-of-sample) indicate that the model does not explain a substantial portion of the variability in cholesterol levels. This suggests that the model’s predictive power is weak. Data Quality and Missing Information:\nMissing data could have impacted model performance, especially for variables like smoking status, hypertension, or vigorous activity. Though imputation was done, it is possible that imputed data may not fully capture the true relationships in the data. Potential Confounding Factors:\nOther important confounders or mediators (such as diet, genetics, medication, or socioeconomic status) may not have been included in the model, leading to residual confounding. This could limit the interpretation of the findings. Measurement of Physical Activity:\nThe measure of vigorous activity used here (self-reported days of activity per week) may not fully capture the intensity, duration, or nature of the physical activity. More granular or objective measures (e.g., wearable fitness trackers) could provide better insights.\nHomogeneity of the Sample:\nThe study sample may not fully represent diverse populations in terms of age, health conditions, or lifestyle, which may limit the generalizability of the findings to broader populations. Model Assumptions:\nThe linear regression model assumes a linear relationship between predictors and the outcome. If these relationships are non-linear or involve complex interactions, a simple linear model may not capture them adequately.\n\n\n8.8.3 Next Steps\nModel Refinement:\nExplore more complex machine learning models, such as decision trees, random forests, or gradient boosting machines, which may capture non-linear relationships and interactions between predictors more effectively. Feature Engineering:\nConsider introducing interaction terms between variables (e.g., between BMI and vigorous activity), or even non-linear transformations of key predictors, such as using BMI as a quadratic term or applying logarithmic transformations to physical activity.\nIncluding Additional Predictors:\nCollect and incorporate additional variables that may better explain cholesterol levels, such as dietary intake, medication usage, or genetic information (e.g., family history of cholesterol-related conditions). Investigating the Relationship Between Physical Activity and Cholesterol:\nConsider investigating more granular measurements of physical activity, such as average minutes per day or intensity levels. This could help assess whether the number of vigorous days per week is the most appropriate metric for modeling cholesterol levels. Longitudinal or Experimental Studies:\nA longitudinal study or a randomized controlled trial (RCT) would be ideal to better understand the causal relationship between physical activity and cholesterol levels over time. These designs could better isolate the effects of physical activity from confounding variables and provide more robust evidence. Addressing Missing Data More Effectively:\nRather than using single imputation, explore more advanced imputation techniques or even data augmentation methods to better handle missing data and improve model accuracy.\n\n\n8.8.4 Reflection\nHad I known at the start of Study 2 what I have learned through the process, I would have approached the analysis with a broader perspective. While the focus was on using linear regression, I would have initially considered a wider range of potential predictors that could better explain the variability in cholesterol levels. Incorporating more comprehensive data, such as dietary habits, medication usage, or family medical history, might have added crucial information to the model and improved its explanatory power. Additionally, I would have conducted more thorough research into the existing literature to identify other factors that may have influenced cholesterol levels, ensuring that the most relevant predictors were included from the beginning.\nFurthermore, I would have sought a larger and more diverse sample to improve the model’s generalizability. This could involve reaching out to different populations or using more advanced data collection techniques to ensure a representative sample. In hindsight, I would also have explored more advanced methods for handling missing data. These changes could have potentially led to a more accurate and insightful analysis of the relationship between physical activity and cholesterol levels.\n\n\n8.8.5 Reasoning for the Dashboard\nIn this study, I decided to split the dashboard into two primary sections: Data Overview and Model. This structure allows for a clear and concise presentation of both the dataset’s key features and the predictive modeling results, offering users a comprehensive understanding of the data and insights drawn from the analysis.\nData Overview The first section, Data Overview, provides an at-a-glance summary of the study participants and key variables, such as BMI, cholesterol levels, and vigorous activity days. The dashboard presents these summaries using value boxes and visualizations, including histograms and bar charts, to facilitate quick understanding of the dataset’s distribution. By highlighting important statistics (e.g., average BMI, cholesterol levels, and activity days), this section gives users a snapshot of the data, allowing them to grasp key trends before delving into the predictive modeling.\nThe categorical summaries (age groups and smoking status) are visualized with bar charts, offering insights into the demographic distribution of the study population. The use of color-coded value boxes for the number of participants, healthy cholesterol levels, and average vigorous activity days helps draw attention to important figures that define the sample.\nModel The second section, Model, presents the results from two linear regression models. This section is tailored for a more technical audience, providing detailed insights into the modeling process, the significance of the variables included, and their respective coefficients.\nThis visualizes the residual plots for both models, helping users assess model fit and interpret the results. Additionally, a model comparison table presents key performance metrics for each model, allowing users to make informed decisions about which model best predicts cholesterol levels.\nThe following code plots the graphs that I will use for this section in the dashboard.\n\n# 1. Residual vs. Fitted Plot\npng(\"imgs/residual_vs_fitted.png\", width = 800, height = 600)\nplot(subset_model$fitted.values, residuals(subset_model), \n     xlab = \"Fitted Values\", ylab = \"Residuals\", \n     main = \"Residual vs Fitted\", pch = 16, col = \"blue\")\npoints(full_model$fitted.values, residuals(full_model), pch = 16, col = \"red\")\nlegend(\"topright\", legend = c(\"Subset Model\", \"Full Model\"), col = c(\"blue\", \"red\"), pch = 16)\nabline(h = 0, col = \"black\")\ndev.off()\n\nquartz_off_screen \n                2 \n\n# 2. Q-Q Plot\npng(\"imgs/qq_plot.png\", width = 800, height = 600)\nqqnorm(residuals(subset_model), main = \"Q-Q Plot\", col = \"blue\", pch = 16)\nqqline(residuals(subset_model), col = \"blue\", lty = 2)\npoints(qqnorm(residuals(full_model), plot.it = FALSE)$x, \n       qqnorm(residuals(full_model), plot.it = FALSE)$y, col = \"red\", pch = 16)\nlegend(\"topleft\", legend = c(\"Subset Model\", \"Full Model\"), col = c(\"blue\", \"red\"), pch = 16)\nqqline(residuals(full_model), col = \"red\", lty = 2)\ndev.off()\n\nquartz_off_screen \n                2 \n\n# 3. Histogram of Residuals\npng(\"imgs/histogram_residuals.png\", width = 800, height = 600)\nhist(residuals(subset_model), main = \"Histogram of Residuals\", xlab = \"Residuals\", \n     col = rgb(0, 0, 1, 0.5), breaks = 20, xlim = range(c(residuals(subset_model), residuals(full_model))))\nhist(residuals(full_model), col = rgb(1, 0, 0, 0.5), add = TRUE, breaks = 20)\nlegend(\"topright\", legend = c(\"Subset Model\", \"Full Model\"), fill = c(rgb(0, 0, 1, 0.5), rgb(1, 0, 0, 0.5)))\ndev.off()\n\nquartz_off_screen \n                2 \n\n# 4. Cook's Distance Plot\npng(\"imgs/cooks_distance.png\", width = 800, height = 600)\nplot(cooks.distance(subset_model), type = \"h\", main = \"Cook's Distance\", \n     ylab = \"Cook's Distance\", xlab = \"Index\", col = \"blue\")\nlines(cooks.distance(full_model), type = \"h\", col = \"red\")\nlegend(\"topright\", legend = c(\"Subset Model\", \"Full Model\"), col = c(\"blue\", \"red\"), lty = 1)\ndev.off()\n\nquartz_off_screen \n                2"
  }
]